{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#quick-start\" data-toc-modified-id=\"quick-start-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>quick start</a></span><ul class=\"toc-item\"><li><span><a href=\"#Resources\" data-toc-modified-id=\"Resources-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Resources</a></span></li></ul></li><li><span><a href=\"#FULL-MODEL\" data-toc-modified-id=\"FULL-MODEL-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>FULL MODEL</a></span><ul class=\"toc-item\"><li><span><a href=\"#Packages\" data-toc-modified-id=\"Packages-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Packages</a></span><ul class=\"toc-item\"><li><span><a href=\"#Qnetwork\" data-toc-modified-id=\"Qnetwork-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Qnetwork</a></span></li></ul></li><li><span><a href=\"#POMDP-RNN-Game\" data-toc-modified-id=\"POMDP-RNN-Game-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>POMDP RNN Game</a></span></li><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Results</a></span><ul class=\"toc-item\"><li><span><a href=\"#Standard-setting：-grid-=--(3,7)，-holes-=-0\" data-toc-modified-id=\"Standard-setting：-grid-=--(3,7)，-holes-=-0-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Standard setting： grid =  (3,7)， holes = 0</a></span></li><li><span><a href=\"#Model-Tranining\" data-toc-modified-id=\"Model-Tranining-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Model Tranining</a></span></li><li><span><a href=\"#decoding-vs-performance\" data-toc-modified-id=\"decoding-vs-performance-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>decoding vs performance</a></span></li><li><span><a href=\"#learning-rate-vs-performance\" data-toc-modified-id=\"learning-rate-vs-performance-2.3.4\"><span class=\"toc-item-num\">2.3.4&nbsp;&nbsp;</span>learning rate vs performance</a></span></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-2.3.5\"><span class=\"toc-item-num\">2.3.5&nbsp;&nbsp;</span>Summary</a></span></li><li><span><a href=\"#Anlytic-part-,-check-the-behaviour-correspond-to-each-decoding-level-and-explain-why\" data-toc-modified-id=\"Anlytic-part-,-check-the-behaviour-correspond-to-each-decoding-level-and-explain-why-2.3.6\"><span class=\"toc-item-num\">2.3.6&nbsp;&nbsp;</span>Anlytic part , check the behaviour correspond to each decoding level and explain why</a></span></li></ul></li><li><span><a href=\"#PCA\" data-toc-modified-id=\"PCA-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>PCA</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quick start "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No information on wall, this very nature case which needs the exploration, try to see its relation of generalization to performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "* [*The* Reinforcement learning book from Sutton & Barto](http://incompleteideas.net/sutton/book/the-book-2nd.html)\n",
    "* [The REINFORCE paper from Ronald J. Williams (1992)](http://www-anw.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tie/anaconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import init\n",
    "from torch.nn import DataParallel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML\n",
    "\n",
    "import pretrain\n",
    "from pretrain import *\n",
    "\n",
    "import navigation2\n",
    "from navigation2 import *\n",
    "\n",
    "import Nets \n",
    "from Nets import * \n",
    "\n",
    "%pylab inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qnetwork\n",
    "\n",
    "To select actions we take maximum of Q value, corresponding to certain move."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the liquid state approach to work, you need a lot of neurons as surplus or enough hidden to hidden connectivity to make it have an effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  POMDP RNN Game\n",
    "\n",
    "In this game , we use a new reward function determined by game, if the agent achieves the goal before 50, reward is 1. If time pass 50 reward is 0.5, once time pass 100 agent gets a reward of -0.5 .  Practically, this is found to be easier to learn than the rewards as a continous function of time.  Tf the agent learns to search in a efficient way, the largest possible way for search is to firstly arrive at corner then goes to the goal, which, takes about 50 steps, it is reasonble to make 50 and 100 as milestone thing.  Also in principe as the game doesn't have a timer , it is not if it can use a reward as funtion of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 condition for ending , when pass time limit, game over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For weight update, it seems to be better do it after episode, as it makes non-sense evaluate strategy during episode, but a the end. Also, it is much quicker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A programming of MDP here, hidden state is as state of enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pregame = PretrainGame(grid_size = (15, 15), holes = 0, random_seed = 4 , set_reward = [(0.5, 0.25), (0.5, 0.75)])\n",
    "pregame.reset(set_agent=(2,2))\n",
    "# rls_q = RLS(1)\n",
    "# rls_sl = RLS(1)\n",
    "# for i in range(1):\n",
    "#     pregame.fulltrain(trials = 4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = ValueMaxGame(pregame.net, grid_size = (15, 15), holes = 0, random_seed = 4 , set_reward =  [(0.5, 0.25), (0.5, 0.75)])\n",
    "game.reset()\n",
    "# game.experiment(rls_q, rls_sl, 20, epsilon = 0.5, lr = 1e-3, train_hidden = False, train_q = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0e3c589eb8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0eaeff62b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(game.grid.grid)\n",
    "# plt.savefig('g16h3-map')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tranining \n",
    "Pretranining is done with fixed size 15,  training is between 10 to 15, test on 19 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training from zero seems to be better because it will allow the agent to explore from new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear session data 49 6478848000\n",
      "0 rewards (0.617624269005848, -0.5997408541541442)\n",
      "clear session data 49 6526386176\n",
      "1 rewards (0.6973489583333334, -0.7396449704142012)\n",
      "clear session data 49 6678491136\n",
      "2 rewards (0.9465767543859649, -0.6163461538461539)\n",
      "clear session data 49 6493630464\n",
      "3 rewards (0.9275413602941177, -0.5730171392000889)\n",
      "clear session data 49 6493630464\n",
      "4 rewards (0.9860359432234432, -0.6568047337278107)\n",
      "clear session data 49 8532094976\n",
      "5 rewards (0.927704730576441, -0.47802919281512435)\n",
      "clear session data 49 8532389888\n",
      "6 rewards (0.8290294117647059, -0.5517529487621287)\n",
      "clear session data 49 8532393984\n",
      "7 rewards (0.9173009868421053, -0.5396711336334743)\n",
      "clear session data 49 8532393984\n",
      "8 rewards (0.7181696428571429, -0.604176939513478)\n",
      "clear session data 49 8532393984\n",
      "9 rewards (0.9486108630952381, -0.6478388027177753)\n",
      "clear session data 49 8532393984\n",
      "10 rewards (0.9883537581699346, -0.6297035144824094)\n",
      "clear session data 49 8532393984\n",
      "11 rewards (0.8980575174148607, -0.6098733075112674)\n",
      "clear session data 49 8608116736\n",
      "12 rewards (0.7680208333333334, -0.6094674556213018)\n",
      "clear session data 49 8501600256\n",
      "13 rewards (0.878126209365325, -0.5740167951706413)\n",
      "clear session data 49 8501600256\n",
      "14 rewards (0.8767842492260063, -0.5409101221551513)\n",
      "clear session data 49 8501600256\n",
      "15 rewards (0.9787708333333334, -0.650887573964497)\n",
      "clear session data 49 8501600256\n",
      "16 rewards (0.7086805555555555, -0.521013702896294)\n",
      "clear session data 49 8501600256\n",
      "17 rewards (0.9733702485380117, -0.5329365211108021)\n",
      "clear session data 49 8501600256\n",
      "18 rewards (0.9241203191803037, -0.6331360946745562)\n",
      "clear session data 49 8501600256\n",
      "19 rewards (0.8861755514705882, -0.6060399695886742)\n",
      "clear session data 49 8501600256\n",
      "0 rewards (0.38648757309941517, -0.7653247789375706)\n",
      "clear session data 49 8501600256\n",
      "1 rewards (0.8065365550825594, -0.6580255856515898)\n",
      "clear session data 49 8501600256\n",
      "2 rewards (0.9586488095238095, -0.6157159146942801)\n",
      "clear session data 49 8501600256\n",
      "3 rewards (0.8563547932330826, -0.4611139664822054)\n",
      "clear session data 49 8501600256\n",
      "4 rewards (0.8575260416666667, -0.4262078314089772)\n",
      "clear session data 49 8501600256\n",
      "5 rewards (0.9473177083333333, -0.3267880039187604)\n",
      "clear session data 49 8501600256\n",
      "6 rewards (0.9184523080065359, -0.5333561841535576)\n",
      "clear session data 49 8501600256\n",
      "7 rewards (0.9595192307692308, -0.4484753812646356)\n",
      "clear session data 49 8501600256\n",
      "8 rewards (0.9475399896800826, -0.4669439859375984)\n",
      "clear session data 49 8501600256\n",
      "9 rewards (0.9083620141038872, -0.33924985374318994)\n",
      "clear session data 49 8501600256\n",
      "10 rewards (0.9695138888888888, -0.5509224865856449)\n",
      "clear session data 49 8501600256\n",
      "11 rewards (0.9732021152759349, -0.6153846153846154)\n",
      "clear session data 49 8501600256\n",
      "12 rewards (0.985530615755074, -0.6450232459847844)\n",
      "clear session data 49 8501600256\n",
      "13 rewards (0.9552617872807018, -0.5295545513001134)\n",
      "clear session data 49 8501600256\n",
      "14 rewards (0.9850257352941176, -0.44652041438928813)\n",
      "clear session data 49 8501600256\n",
      "15 rewards (0.9367445874183007, -0.5472136469635559)\n",
      "clear session data 49 8501600256\n",
      "16 rewards (0.9766110089869282, -0.6951097350815458)\n",
      "clear session data 49 8501600256\n",
      "17 rewards (0.9691805555555555, -0.39753001610082034)\n",
      "clear session data 49 8501862400\n",
      "18 rewards (0.9079704861111111, -0.5414306106902794)\n",
      "clear session data 49 8501862400\n",
      "19 rewards (0.7845430281846206, -0.45291423782592555)\n",
      "clear session data 49 8501862400\n",
      "0 rewards (0.689171875, -0.6653582043395767)\n",
      "clear session data 49 8501862400\n",
      "1 rewards (0.9342406798245614, -0.6061718658280939)\n",
      "clear session data 49 8501862400\n",
      "2 rewards (0.9691875000000001, -0.6982248520710059)\n",
      "clear session data 49 8501862400\n",
      "3 rewards (0.8388970588235294, -0.6110765206298077)\n",
      "clear session data 49 8501862400\n",
      "4 rewards (0.9177169117647059, -0.5919473247059455)\n",
      "clear session data 49 8501862400\n",
      "5 rewards (0.96, -0.6568047337278107)\n",
      "clear session data 49 8501862400\n",
      "6 rewards (0.7384571884674923, -0.5857988165680473)\n",
      "clear session data 49 8501862400\n",
      "7 rewards (0.7589934210526316, -0.5503503581438804)\n",
      "clear session data 49 8501862400\n",
      "8 rewards (0.9183215460526315, -0.515231690828308)\n",
      "clear session data 49 8501862400\n",
      "9 rewards (0.988046052631579, -0.5069740193846471)\n",
      "clear session data 49 8501862400\n",
      "10 rewards (0.6552286560457516, -0.5741146333093449)\n",
      "clear session data 49 8501862400\n",
      "11 rewards (0.9682386304302423, -0.4437869822485207)\n",
      "clear session data 49 8501862400\n",
      "12 rewards (0.8376589912280701, -0.6219018273674144)\n",
      "clear session data 49 8501862400\n",
      "13 rewards (0.8427130256707946, -0.6153846153846154)\n",
      "clear session data 49 8501862400\n",
      "14 rewards (0.7176502192982457, -0.47957827850287366)\n",
      "clear session data 49 8501862400\n",
      "15 rewards (0.8997794117647059, -0.4323390538615336)\n",
      "clear session data 49 8501862400\n",
      "16 rewards (0.9288337418300654, -0.6094674556213018)\n",
      "clear session data 49 8501862400\n",
      "17 rewards (0.9664673632610938, -0.627824746857071)\n",
      "clear session data 49 8617373696\n",
      "18 rewards (0.816265037593985, -0.6391346153846154)\n",
      "clear session data 49 8617373696\n",
      "19 rewards (0.9390290178571428, -0.5511020710059172)\n"
     ]
    }
   ],
   "source": [
    "for iters, noise in enumerate(3 * [0.0]):\n",
    "    for trial in [212]: \n",
    "        Pretest =  PretrainTest(holes = 0, weight_write = 'weights_cpu/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        weight_read = Pretest.weight\n",
    "        weight_write = 'weights2/rnn_1515tanh512_checkpoint{}_{}'.format(trial, iters)\n",
    "        rewards = Pretest.qlearn(weight_read,  weight_write, iterations = 20, noise = noise, size_train = np.arange(10, 51, 10), size_test=[10, 50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear session data 49 8498638848\n",
      "0 rewards (0.5840880847953216, -0.6099328696494688)\n",
      "clear session data 49 8498638848\n",
      "1 rewards (0.755546256879945, -0.4224338022152576)\n",
      "clear session data 49 8498638848\n",
      "2 rewards (0.9792543859649123, -0.6522628950578631)\n",
      "clear session data 49 8498638848\n",
      "3 rewards (0.887046875, -0.5333442559255406)\n",
      "clear session data 49 8498638848\n",
      "4 rewards (0.7891720085470085, -0.5454695405722143)\n",
      "clear session data 49 8498638848\n",
      "5 rewards (0.8288521634615384, -0.3798038386599836)\n",
      "clear session data 49 8498638848\n",
      "6 rewards (0.7766673116615067, -0.39865585327961306)\n",
      "clear session data 49 8498638848\n",
      "7 rewards (0.8179600563909775, -0.5449907029481735)\n",
      "clear session data 49 8498638848\n",
      "8 rewards (0.7464732142857142, -0.3609467455621302)\n",
      "clear session data 49 8498638848\n",
      "9 rewards (0.9379093567251462, -0.5199849941944097)\n",
      "clear session data 49 8498900992\n",
      "10 rewards (0.9273080065359477, -0.560392030675942)\n",
      "clear session data 49 8498900992\n",
      "11 rewards (0.9142682748538011, -0.6451573574354639)\n",
      "clear session data 49 8498900992\n",
      "12 rewards (0.88, -0.5564675708906478)\n",
      "clear session data 49 8498900992\n",
      "13 rewards (0.6976041666666667, -0.3178015786499603)\n",
      "clear session data 49 8498900992\n",
      "14 rewards (0.9863725490196079, -0.5976331360946745)\n",
      "clear session data 49 8498900992\n",
      "15 rewards (0.9588281249999999, -0.40700337638458206)\n",
      "clear session data 49 8498900992\n",
      "16 rewards (0.9492795138888889, -0.6272189349112427)\n",
      "clear session data 49 8498900992\n",
      "17 rewards (0.9159411280959753, -0.5637918834920438)\n",
      "clear session data 49 8498900992\n",
      "18 rewards (0.9828922751117992, -0.45003609876231154)\n",
      "clear session data 49 8498900992\n",
      "19 rewards (0.9067045940170939, -0.5375595631928917)\n",
      "clear session data 49 8498900992\n",
      "0 rewards (0.5496875, -0.6451659525266953)\n",
      "clear session data 49 8498900992\n",
      "1 rewards (0.45, -0.7936642684238838)\n",
      "clear session data 49 8498900992\n",
      "2 rewards (-0.32, -0.8579881656804733)\n",
      "clear session data 49 8498900992\n",
      "3 rewards (-0.62, -0.9171597633136095)\n",
      "clear session data 49 8498900992\n",
      "4 rewards (0.36, -0.7278106508875739)\n",
      "clear session data 49 8498900992\n",
      "5 rewards (0.41000000000000003, -0.6509253109527835)\n",
      "clear session data 49 8774356992\n",
      "6 rewards (0.8831648391812865, -0.5168034202116134)\n",
      "clear session data 49 8498937856\n",
      "7 rewards (0.9838717105263158, -0.5358471738441908)\n",
      "clear session data 49 8498937856\n",
      "8 rewards (0.7983461718020541, -0.17534440602402718)\n",
      "clear session data 49 8498937856\n",
      "9 rewards (0.7434923245614036, -0.5152913192576654)\n",
      "clear session data 49 8498937856\n",
      "10 rewards (0.9780270538124156, -0.5857988165680473)\n",
      "clear session data 49 8498937856\n",
      "11 rewards (0.8766041666666666, -0.6627218934911243)\n",
      "clear session data 49 8498937856\n",
      "12 rewards (0.9467482638888889, -0.6568047337278107)\n",
      "clear session data 49 8498937856\n",
      "13 rewards (0.9374402573529411, -0.6094674556213018)\n",
      "clear session data 49 8498937856\n",
      "14 rewards (0.9985701593137255, -0.6392582162971412)\n",
      "clear session data 49 8498937856\n",
      "15 rewards (0.9757916666666666, -0.5976331360946745)\n",
      "clear session data 49 8498937856\n",
      "16 rewards (0.9034923191864465, -0.6393286541608965)\n",
      "clear session data 49 8498937856\n",
      "17 rewards (0.9692459514170041, -0.38440447234254826)\n",
      "clear session data 49 8498937856\n",
      "18 rewards (0.9371156636996905, -0.5693362126655397)\n",
      "clear session data 49 8498937856\n",
      "19 rewards (0.7863847824217407, -0.4837644682494191)\n",
      "clear session data 49 8498937856\n",
      "0 rewards (0.8439254493464052, -0.6334272315246129)\n",
      "clear session data 49 8498937856\n",
      "1 rewards (0.6876102941176472, -0.6863905325443787)\n",
      "clear session data 49 8676933632\n",
      "2 rewards (0.6765064929480564, -0.49270566102413405)\n",
      "clear session data 49 8676933632\n",
      "3 rewards (0.8607022918816649, -0.5563196450479975)\n",
      "clear session data 49 8498978816\n",
      "4 rewards (0.8341995506535947, -0.5983413068110286)\n",
      "clear session data 49 8739913728\n",
      "5 rewards (0.6959769736842105, -0.5109293173630399)\n",
      "clear session data 49 8637935616\n",
      "6 rewards (0.9158877010233918, -0.5798816568047338)\n",
      "clear session data 49 8498790400\n",
      "7 rewards (0.8848156980994153, -0.46772311817560686)\n",
      "clear session data 49 8498790400\n",
      "8 rewards (0.989375, -0.6804733727810651)\n",
      "clear session data 49 8529760256\n",
      "9 rewards (0.696609375, -0.7191926750637054)\n",
      "clear session data 49 8529727488\n",
      "10 rewards (0.6796527777777778, -0.5976331360946745)\n",
      "clear session data 49 8529727488\n",
      "11 rewards (0.9175559210526316, -0.48176364486472556)\n",
      "clear session data 49 8529727488\n",
      "12 rewards (0.8231566945857292, -0.3852179536634744)\n",
      "clear session data 49 8529727488\n",
      "13 rewards (0.9379736842105263, -0.49165491096025393)\n",
      "clear session data 49 8529727488\n",
      "14 rewards (0.7377184614061549, -0.4978429330201154)\n",
      "clear session data 49 8529727488\n",
      "15 rewards (0.9188958333333334, -0.5814747267829186)\n",
      "clear session data 49 8529727488\n",
      "16 rewards (0.9650081323099415, -0.6925542406311638)\n",
      "clear session data 49 8529727488\n",
      "17 rewards (0.90984492481203, -0.5865922081581423)\n",
      "clear session data 49 8529727488\n",
      "18 rewards (0.9268971125730994, -0.5269609611776591)\n",
      "clear session data 49 8529989632\n",
      "19 rewards (0.593140243378053, -0.6153846153846154)\n"
     ]
    }
   ],
   "source": [
    "for iters, noise in enumerate(3 * [0.0]):\n",
    "    for trial in [399]: \n",
    "        Pretest =  PretrainTest(holes = 0, weight_write = 'weights_cpu/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        weight_read = Pretest.weight\n",
    "        weight_write = 'weights2/rnn_1515tanh512_checkpoint{}_{}'.format(trial, iters)\n",
    "        rewards = Pretest.qlearn(weight_read,  weight_write, iterations = 20, noise = noise, size_train = np.arange(10, 51, 10), size_test=[10, 50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear session data 49 5386268672\n",
      "0 rewards (0.26597407882687485, -0.6681614812177559)\n",
      "clear session data 49 5199532032\n",
      "1 rewards (0.1776813080495356, -0.7233334112263476)\n",
      "clear session data 49 6193930240\n",
      "2 rewards (0.29647600081699343, -0.4751468222907394)\n",
      "clear session data 49 6193930240\n",
      "3 rewards (0.3953331613347093, -0.5782788092641373)\n",
      "clear session data 49 6193930240\n",
      "4 rewards (0.5477220394736843, -0.6867059693699965)\n",
      "clear session data 49 7708680192\n",
      "5 rewards (0.7763047969187674, -0.6153846153846154)\n",
      "clear session data 49 7708749824\n",
      "6 rewards (0.705501177115583, -0.5393645640463175)\n",
      "clear session data 49 7500447744\n",
      "7 rewards (0.8417731338149295, -0.5081731468802997)\n",
      "clear session data 49 7500447744\n",
      "8 rewards (0.9381273881347412, -0.4718328187552017)\n",
      "clear session data 49 8486064128\n",
      "9 rewards (0.788828125, -0.5342671992920922)\n",
      "clear session data 49 8486133760\n",
      "10 rewards (0.7068774671052631, -0.3517047481215423)\n",
      "clear session data 49 8486133760\n",
      "11 rewards (0.5468958333333334, -0.4475044343160145)\n",
      "clear session data 49 8486133760\n",
      "12 rewards (0.739765625, -0.33324650213433415)\n",
      "clear session data 49 8486133760\n",
      "13 rewards (0.6065852521929824, -0.3411143291488439)\n",
      "clear session data 49 8486133760\n",
      "14 rewards (0.7265359477124183, -0.5497642740545612)\n",
      "clear session data 49 8486133760\n",
      "15 rewards (0.6789174836601306, -0.5060521364989947)\n",
      "clear session data 49 8486133760\n",
      "16 rewards (0.6985906862745098, -0.41319895857212796)\n",
      "clear session data 49 8486395904\n",
      "17 rewards (0.6695138888888889, -0.3601100896906053)\n",
      "clear session data 49 8486395904\n",
      "18 rewards (0.6169148821809426, -0.5275499308450549)\n",
      "clear session data 49 8486395904\n",
      "19 rewards (0.6091646634615384, -0.11783428950139968)\n",
      "clear session data 49 7773462528\n",
      "0 rewards (0.36606798245614036, -0.42495550438456525)\n",
      "clear session data 49 7773462528\n",
      "1 rewards (0.5635413326514817, -0.5381742627955877)\n",
      "clear session data 49 7773462528\n",
      "2 rewards (0.7167735745614034, -0.31516918425943746)\n",
      "clear session data 49 7773462528\n",
      "3 rewards (0.743954137145749, -0.34681074533954315)\n",
      "clear session data 49 7773462528\n",
      "4 rewards (0.7776362820347438, -0.2442162028291689)\n",
      "clear session data 49 7773462528\n",
      "5 rewards (0.8063483455882353, -0.37268012629986547)\n",
      "clear session data 49 7773462528\n",
      "6 rewards (0.8177206558061823, -0.46042942987402025)\n",
      "clear session data 49 7773462528\n",
      "7 rewards (0.8673783700980393, -0.4003512522449164)\n",
      "clear session data 49 7773462528\n",
      "8 rewards (0.7244012082903337, -0.3782846044150081)\n",
      "clear session data 49 7773462528\n",
      "9 rewards (0.605923611111111, -0.4884743502396679)\n",
      "clear session data 49 7773462528\n",
      "10 rewards (0.839280427631579, -0.5828841898590356)\n",
      "clear session data 49 7773462528\n",
      "11 rewards (0.8294531249999999, -0.45242190129328097)\n",
      "clear session data 49 7773462528\n",
      "12 rewards (0.7068621162280702, -0.5455867095127512)\n",
      "clear session data 49 7773462528\n",
      "13 rewards (0.7496875000000001, -0.5632761193544377)\n",
      "clear session data 49 7773462528\n",
      "14 rewards (0.755827394005848, -0.5243147745809216)\n",
      "clear session data 49 7773462528\n",
      "15 rewards (0.9175819143446853, -0.5516167216520039)\n",
      "clear session data 49 7849668608\n",
      "16 rewards (0.7955507127192982, -0.5118188959218338)\n",
      "clear session data 49 7849668608\n",
      "17 rewards (0.7767630718954248, -0.3995140585752648)\n",
      "clear session data 49 7772094464\n",
      "18 rewards (0.6954960010319917, -0.5085782459056043)\n",
      "clear session data 49 7772094464\n",
      "19 rewards (0.7059882933436532, -0.3254216086851354)\n",
      "clear session data 49 7615852544\n",
      "0 rewards (0.48903379772961814, -0.4502955672156824)\n",
      "clear session data 49 7615852544\n",
      "1 rewards (0.6964948830409357, -0.5266690859982779)\n",
      "clear session data 49 7615852544\n",
      "2 rewards (0.7456487511671335, -0.3715251533975808)\n",
      "clear session data 49 7615852544\n",
      "3 rewards (0.6792269736842106, -0.4821665796806698)\n",
      "clear session data 49 7615852544\n",
      "4 rewards (0.8972561274509804, -0.4649447802506751)\n",
      "clear session data 49 7615852544\n",
      "5 rewards (0.8640715291599095, -0.5030059930207859)\n",
      "clear session data 49 7615852544\n",
      "6 rewards (0.7748097587719298, -0.408918172811176)\n",
      "clear session data 49 7615852544\n",
      "7 rewards (0.8082236842105264, -0.3028856428046507)\n",
      "clear session data 49 7615852544\n",
      "8 rewards (0.7893749999999999, -0.4272601196880043)\n",
      "clear session data 49 7615852544\n",
      "9 rewards (0.795625, -0.2359559519805309)\n",
      "clear session data 49 7615852544\n",
      "10 rewards (0.809279411764706, -0.4658837453601071)\n",
      "clear session data 49 7615852544\n",
      "11 rewards (0.5166896284829722, -0.35968588383554884)\n",
      "clear session data 49 7615852544\n",
      "12 rewards (0.5883767361111112, -0.3454434823681045)\n",
      "clear session data 49 7616114688\n",
      "13 rewards (0.8477806372549019, -0.23026870661373616)\n",
      "clear session data 49 7616114688\n",
      "14 rewards (0.8073849759201926, -0.4068128067257573)\n",
      "clear session data 49 7616114688\n",
      "15 rewards (0.747610387145749, -0.49317657715095237)\n",
      "clear session data 49 7616114688\n",
      "16 rewards (0.8272032217492261, -0.5303646845004668)\n",
      "clear session data 49 7616114688\n",
      "17 rewards (0.7385062134502924, -0.1835815427166786)\n",
      "clear session data 49 7616114688\n",
      "18 rewards (0.7386041666666667, -0.5471910007446199)\n",
      "clear session data 49 7616114688\n",
      "19 rewards (0.875985331742346, -0.5274123182777029)\n"
     ]
    }
   ],
   "source": [
    "for iters, noise in enumerate(3 * [0.0]):\n",
    "    for trial in [0]: \n",
    "        Pretest =  PretrainTest(holes = 0, weight_write = 'weights_cpu/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        weight_read = Pretest.weight\n",
    "        weight_write = 'weights2/rnn_1515tanh512_checkpoint{}_{}'.format(trial, iters)\n",
    "        rewards = Pretest.qlearn(weight_read,  weight_write, iterations = 20, noise = noise, size_train = np.arange(10, 51, 10), size_test=[10, 50])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "759px",
    "left": "0px",
    "right": "1228px",
    "top": "67px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
