{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#quick-start\" data-toc-modified-id=\"quick-start-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>quick start</a></span><ul class=\"toc-item\"><li><span><a href=\"#Resources\" data-toc-modified-id=\"Resources-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Resources</a></span></li></ul></li><li><span><a href=\"#FULL-MODEL\" data-toc-modified-id=\"FULL-MODEL-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>FULL MODEL</a></span><ul class=\"toc-item\"><li><span><a href=\"#Packages\" data-toc-modified-id=\"Packages-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Packages</a></span><ul class=\"toc-item\"><li><span><a href=\"#Qnetwork\" data-toc-modified-id=\"Qnetwork-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Qnetwork</a></span></li></ul></li><li><span><a href=\"#POMDP-RNN-Game\" data-toc-modified-id=\"POMDP-RNN-Game-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>POMDP RNN Game</a></span></li><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Results</a></span><ul class=\"toc-item\"><li><span><a href=\"#Standard-setting：-grid-=--(3,7)，-holes-=-0\" data-toc-modified-id=\"Standard-setting：-grid-=--(3,7)，-holes-=-0-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Standard setting： grid =  (3,7)， holes = 0</a></span></li><li><span><a href=\"#Model-Tranining\" data-toc-modified-id=\"Model-Tranining-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Model Tranining</a></span></li><li><span><a href=\"#decoding-vs-performance\" data-toc-modified-id=\"decoding-vs-performance-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>decoding vs performance</a></span></li><li><span><a href=\"#learning-rate-vs-performance\" data-toc-modified-id=\"learning-rate-vs-performance-2.3.4\"><span class=\"toc-item-num\">2.3.4&nbsp;&nbsp;</span>learning rate vs performance</a></span></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-2.3.5\"><span class=\"toc-item-num\">2.3.5&nbsp;&nbsp;</span>Summary</a></span></li><li><span><a href=\"#Anlytic-part-,-check-the-behaviour-correspond-to-each-decoding-level-and-explain-why\" data-toc-modified-id=\"Anlytic-part-,-check-the-behaviour-correspond-to-each-decoding-level-and-explain-why-2.3.6\"><span class=\"toc-item-num\">2.3.6&nbsp;&nbsp;</span>Anlytic part , check the behaviour correspond to each decoding level and explain why</a></span></li></ul></li><li><span><a href=\"#PCA\" data-toc-modified-id=\"PCA-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>PCA</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quick start "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No information on wall, this very nature case which needs the exploration, try to see its relation of generalization to performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "* [*The* Reinforcement learning book from Sutton & Barto](http://incompleteideas.net/sutton/book/the-book-2nd.html)\n",
    "* [The REINFORCE paper from Ronald J. Williams (1992)](http://www-anw.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cruiser/anaconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import init\n",
    "from torch.nn import DataParallel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML\n",
    "\n",
    "import pretrain\n",
    "from pretrain import *\n",
    "\n",
    "import navigation2\n",
    "from navigation2 import *\n",
    "\n",
    "import Nets \n",
    "from Nets import * \n",
    "\n",
    "%pylab inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qnetwork\n",
    "\n",
    "To select actions we take maximum of Q value, corresponding to certain move."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the liquid state approach to work, you need a lot of neurons as surplus or enough hidden to hidden connectivity to make it have an effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  POMDP RNN Game\n",
    "\n",
    "In this game , we use a new reward function determined by game, if the agent achieves the goal before 50, reward is 1. If time pass 50 reward is 0.5, once time pass 100 agent gets a reward of -0.5 .  Practically, this is found to be easier to learn than the rewards as a continous function of time.  Tf the agent learns to search in a efficient way, the largest possible way for search is to firstly arrive at corner then goes to the goal, which, takes about 50 steps, it is reasonble to make 50 and 100 as milestone thing.  Also in principe as the game doesn't have a timer , it is not if it can use a reward as funtion of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 condition for ending , when pass time limit, game over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For weight update, it seems to be better do it after episode, as it makes non-sense evaluate strategy during episode, but a the end. Also, it is much quicker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A programming of MDP here, hidden state is as state of enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pregame = PretrainGame(grid_size = (15, 15), holes = 0, random_seed = 4 , set_reward = [(0.5, 0.25), (0.5, 0.75)])\n",
    "pregame.reset(set_agent=(2,2))\n",
    "# rls_q = RLS(1)\n",
    "# rls_sl = RLS(1)\n",
    "# for i in range(1):\n",
    "#     pregame.fulltrain(trials = 4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = ValueMaxGame(pregame.net, grid_size = (15, 15), holes = 0, random_seed = 4 , set_reward =  [(0.5, 0.25), (0.5, 0.75)])\n",
    "game.reset()\n",
    "# game.experiment(rls_q, rls_sl, 20, epsilon = 0.5, lr = 1e-3, train_hidden = False, train_q = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5ac4082208>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAAECCAYAAAAYUakXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5b306954e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(game.grid.grid)\n",
    "# plt.savefig('g16h3-map')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Tranining \n",
    "Pretranining is done with fixed size 15,  training is between 10 to 15, test on 19 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training from zero seems to be better because it will allow the agent to explore from new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear session data 49 8014520320\n",
      "0 rewards (0.70775816993464047, -0.58743632131773105)\n",
      "clear session data 49 8014782464\n",
      "1 rewards (0.84480729166666668, -0.47554287327577194)\n",
      "clear session data 49 8014856192\n",
      "2 rewards (0.85838815789473677, -0.57429482910252139)\n",
      "clear session data 49 8014856192\n",
      "3 rewards (0.94659763071895431, -0.46225049398009899)\n",
      "clear session data 49 8014856192\n",
      "4 rewards (0.88314413484692122, -0.46399090320433678)\n",
      "clear session data 49 8014856192\n",
      "5 rewards (0.94693850511695909, -0.42810030108906955)\n",
      "clear session data 49 8014856192\n",
      "6 rewards (0.92999999999999994, -0.52071005917159763)\n",
      "clear session data 49 8014856192\n",
      "7 rewards (0.90101231325863673, -0.43866298300845707)\n",
      "clear session data 49 8014856192\n",
      "8 rewards (0.98708639705882351, -0.6272189349112427)\n",
      "clear session data 49 8496320512\n",
      "9 rewards (0.9579791666666666, -0.32668934432246671)\n",
      "clear session data 49 8496418816\n",
      "0 rewards (0.47891466346153849, -0.61015073248711582)\n",
      "clear session data 49 8496422912\n",
      "1 rewards (0.56557783321662003, -0.69832100591715973)\n",
      "clear session data 49 8496422912\n",
      "2 rewards (0.75977941176470587, -0.73964497041420119)\n",
      "clear session data 49 8496422912\n",
      "3 rewards (0.79722314836865915, -0.64520679558348071)\n",
      "clear session data 49 8496685056\n",
      "4 rewards (0.91668969298245617, -0.47439434882582948)\n",
      "clear session data 49 8496685056\n",
      "5 rewards (0.8740410861713106, -0.69848901098901106)\n",
      "clear session data 49 8496685056\n",
      "6 rewards (0.92713304631062954, -0.72200786921246873)\n",
      "clear session data 49 8496685056\n",
      "7 rewards (0.92941666666666667, -0.71597633136094674)\n",
      "clear session data 49 8496685056\n",
      "8 rewards (0.92747395833333335, -0.71005917159763321)\n",
      "clear session data 49 8496685056\n",
      "9 rewards (0.92909926470588244, -0.70433665524758649)\n"
     ]
    }
   ],
   "source": [
    "for iters, noise in enumerate(3 * [0.0]):\n",
    "    for trial in [83]: \n",
    "        Pretest =  PretrainTest(holes = 0, weight_write = 'weights_cpu/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        weight_read = Pretest.weight\n",
    "        weight_write = 'weights2/rnn_1515tanh512_checkpoint{}_{}'.format(trial, iters)\n",
    "        rewards = Pretest.qlearn(weight_read,  weight_write, iterations = 10, noise = noise, size_train = np.arange(10, 51, 20), size_test=[10, 50])\n",
    "        np.save('Rewards_l_{}_{}.npy'.format(iters, trial), rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear session data 49 6494257152\n",
      "0 rewards (0.65636478758169936, -0.60744100493960507)\n",
      "clear session data 49 6494359552\n",
      "1 rewards (0.78438996388028892, -0.68233885533788063)\n",
      "clear session data 49 8837349376\n",
      "2 rewards (0.86496527777777776, -0.62422073352750762)\n",
      "clear session data 49 8837775360\n",
      "3 rewards (0.93840277777777781, -0.67579832437450782)\n",
      "clear session data 49 8837775360\n",
      "4 rewards (0.92827083333333338, -0.63412211313180222)\n",
      "clear session data 49 8837513216\n",
      "5 rewards (0.80653618421052631, -0.59335437887788767)\n",
      "clear session data 49 8837775360\n",
      "6 rewards (0.95729961622807025, -0.58738728005862639)\n",
      "clear session data 49 8837775360\n",
      "7 rewards (0.98776315789473679, -0.63512413957125502)\n",
      "clear session data 49 8837775360\n",
      "8 rewards (0.89785197368421055, -0.66437639333376675)\n",
      "clear session data 49 8837775360\n",
      "9 rewards (0.90398326775885796, -0.65900525222640605)\n",
      "clear session data 49 8837775360\n",
      "0 rewards (0.85949107142857151, -0.64164788252517924)\n",
      "clear session data 49 8837775360\n",
      "1 rewards (0.91624908088235291, -0.64006851237151419)\n",
      "clear session data 49 8837775360\n",
      "2 rewards (0.8892916666666667, -0.66272189349112431)\n",
      "clear session data 49 8837775360\n",
      "3 rewards (0.89720680147058829, -0.66272189349112431)\n",
      "clear session data 49 8837775360\n",
      "4 rewards (0.99577322146807445, -0.72781065088757391)\n",
      "clear session data 49 8837775360\n",
      "5 rewards (0.89789522058823534, -0.63905325443786976)\n",
      "clear session data 49 8837775360\n",
      "6 rewards (0.80626096491228072, -0.74556213017751483)\n",
      "clear session data 49 8837775360\n",
      "7 rewards (0.90360135432378064, -0.66863905325443795)\n",
      "clear session data 49 8837775360\n",
      "8 rewards (0.95651219040247681, -0.81065088757396442)\n",
      "clear session data 49 8837775360\n",
      "9 rewards (0.94561805555555556, -0.70414201183431957)\n",
      "clear session data 49 8837775360\n",
      "0 rewards (0.90650483911513313, -0.75153158807004949)\n"
     ]
    }
   ],
   "source": [
    "for iters, noise in enumerate(3 * [0.0]):\n",
    "    for trial in [300]: \n",
    "        Pretest =  PretrainTest(holes = 0, weight_write = 'weights_cpu/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        weight_read = Pretest.weight\n",
    "        weight_write = 'weights2/rnn_1515tanh512_checkpoint{}_{}'.format(trial, iters)\n",
    "        rewards = Pretest.qlearn(weight_read,  weight_write, iterations = 10, noise = noise, size_train = np.arange(10, 51, 20), size_test=[10, 50])\n",
    "        np.save('Rewards_l_{}_{}.npy'.format(iters, trial), rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear session data 49 3544981504\n",
      "0 rewards (0.67881578947368426, -0.42000000000000004)\n",
      "clear session data 49 3545014272\n",
      "1 rewards (0.85294534206226347, -0.42000000000000004)\n",
      "clear session data 49 3545014272\n",
      "2 rewards (0.8577552083333333, -0.35113839285714288)\n",
      "clear session data 49 4291399680\n",
      "3 rewards (0.98908333333333331, -0.062053146376970569)\n",
      "clear session data 49 4291399680\n",
      "4 rewards (0.97919117647058829, 0.020718528033158136)\n",
      "clear session data 49 4291399680\n",
      "5 rewards (0.98895833333333338, -0.22017156862745096)\n",
      "clear session data 49 4291399680\n",
      "6 rewards (0.94848684210526313, -0.30016022727272729)\n",
      "clear session data 49 4291399680\n",
      "7 rewards (0.93812499999999999, -0.17090342925963492)\n",
      "clear session data 49 4291399680\n",
      "8 rewards (0.93840525191183088, -0.37)\n",
      "clear session data 49 4291399680\n",
      "9 rewards (0.88824479166666659, -0.38)\n",
      "clear session data 49 4440875008\n",
      "0 rewards (0.87243165204678363, -0.32212756467439785)\n",
      "clear session data 49 4440875008\n",
      "1 rewards (0.99635661764705885, -0.13)\n",
      "clear session data 49 4702019584\n",
      "2 rewards (0.99948214285714287, -0.1654194093252325)\n",
      "clear session data 49 4702019584\n",
      "3 rewards (0.98895833333333338, -0.28148901845675911)\n",
      "clear session data 49 4702019584\n",
      "4 rewards (0.97999999999999998, -0.15492155480713213)\n",
      "clear session data 49 4702019584\n",
      "5 rewards (0.99948529411764708, -0.19046610169491526)\n",
      "clear session data 49 4702019584\n",
      "6 rewards (0.98725548245614037, 0.097114174020424021)\n",
      "clear session data 49 4702019584\n",
      "7 rewards (0.93890196078431365, -0.070250000000000007)\n",
      "clear session data 49 4702019584\n",
      "8 rewards (0.97948529411764707, 0.054120075727722178)\n",
      "clear session data 49 4702019584\n",
      "9 rewards (0.99776838235294119, -0.061593084802830551)\n",
      "clear session data 49 4702019584\n",
      "0 rewards (0.47702027740920927, -0.39000000000000001)\n",
      "clear session data 49 4702019584\n",
      "1 rewards (0.96579160216718263, -0.40020833333333328)\n",
      "clear session data 49 4702019584\n",
      "2 rewards (0.96895833333333337, -0.43283007948986718)\n",
      "clear session data 49 4702019584\n",
      "3 rewards (0.98841094771241833, -0.11334851740262515)\n",
      "clear session data 49 4702019584\n",
      "4 rewards (0.99738075657894742, -0.080546568627450979)\n",
      "clear session data 49 4702019584\n",
      "5 rewards (0.99869618055555553, -0.16632517350599613)\n",
      "clear session data 49 4702019584\n",
      "6 rewards (0.97603737745098051, -0.013745689320032589)\n",
      "clear session data 49 4702019584\n",
      "7 rewards (1.0, 0.028728448275862063)\n",
      "clear session data 49 4702019584\n",
      "8 rewards (1.0, -0.18198892537784345)\n",
      "clear session data 49 4702019584\n",
      "9 rewards (0.9784714052287582, -0.16189120926243566)\n"
     ]
    }
   ],
   "source": [
    "for iters, noise in enumerate(3 * [0.0]):\n",
    "    for trial in [300]: \n",
    "        Pretest =  PretrainTest(holes = 0, weight_write = 'weights_cpu/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        weight_read = Pretest.weight\n",
    "        weight_write = 'weights2/rnn_1515tanh512_checkpoint{}_{}'.format(trial, iters+5)\n",
    "        rewards = Pretest.qlearn(weight_read,  weight_write, iterations = 10, noise = noise, size_train = np.arange(10, 31, 20), size_test=[10, 30])\n",
    "        np.save('Rewards_l_{}_{}.npy'.format(iters, trial), rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear session data 49 3622072320\n",
      "0 rewards (0.88901315789473689, -0.091392548635307796)\n",
      "clear session data 49 4275249152\n",
      "1 rewards (0.82694311145510824, 0.103337702286123)\n",
      "clear session data 49 4275249152\n",
      "2 rewards (0.96497489357585142, -0.17084134615384616)\n",
      "clear session data 49 4275249152\n",
      "3 rewards (0.93674672665118686, -0.042164679744110353)\n",
      "clear session data 49 4275249152\n",
      "4 rewards (0.96836729691876755, -0.10327649815396342)\n",
      "clear session data 49 4275249152\n",
      "5 rewards (0.92751807598039215, 0.045458771721348934)\n",
      "clear session data 49 4275249152\n",
      "6 rewards (0.86761038011695901, -0.11180461393596988)\n",
      "clear session data 49 4275249152\n",
      "7 rewards (0.83871527777777777, -0.1503177966101695)\n",
      "clear session data 49 4275249152\n",
      "8 rewards (0.6194567307692308, -0.17064583333333333)\n",
      "clear session data 49 4275249152\n",
      "9 rewards"
     ]
    }
   ],
   "source": [
    "for iters, noise in enumerate(3 * [0.0]):\n",
    "    for trial in [300]: \n",
    "        Pretest =  PretrainTest(holes = 0, weight_write = 'weights_cpu/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        weight_read = Pretest.weight\n",
    "        weight_write = 'weights3/rnn_1515tanh512_checkpoint{}_{}'.format(trial, iters+5)\n",
    "        rewards = Pretest.qlearn(weight_read,  weight_write, iterations = 10, noise = noise, size_train = np.arange(10, 31, 20), size_test=[10, 30],\n",
    "                                feedback = False)\n",
    "        np.save('Rewards_l_{}_{}.npy'.format(iters, trial), rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear session data 49 8049491968\n",
      "0 rewards (0.59821226780185754, -0.51586159948110499)\n",
      "clear session data 49 8049528832\n",
      "1 rewards (0.57804508513931885, -0.58685344401437523)\n",
      "clear session data 49 8049528832\n",
      "2 rewards (0.53370860745614035, -0.56386070188592585)\n",
      "clear session data 49 8049528832\n",
      "3 rewards (0.50500980392156869, -0.42286895427778892)\n",
      "clear session data 49 8049528832\n",
      "4 rewards (0.62570065789473683, -0.49454729168451994)\n",
      "clear session data 49 8049528832\n",
      "5 rewards (0.7086458333333332, -0.51689712029365853)\n",
      "clear session data 49 8049528832\n",
      "6 rewards (0.70851562499999998, -0.47142364921080715)\n",
      "clear session data 49 8049528832\n",
      "7 rewards (0.63900452488687787, -0.38261510034026214)\n",
      "clear session data 49 8049528832\n",
      "8 rewards (0.58651361476608188, -0.44365928678893252)\n",
      "clear session data 49 8049528832\n",
      "9 rewards (0.6886677631578948, -0.43874007936507936)\n",
      "clear session data 49 8049528832\n",
      "0 rewards (0.5277251838235294, -0.59288096980999438)\n",
      "clear session data 49 8049528832\n",
      "1 rewards (0.34782638888888889, -0.6074110701654063)\n",
      "clear session data 49 8049528832\n",
      "2 rewards (0.60771284829721361, -0.582437966273465)\n",
      "clear session data 49 8049528832\n",
      "3 rewards (0.50841419956140355, -0.51020038821491864)\n",
      "clear session data 49 8049528832\n",
      "4 rewards (0.67705729166666662, -0.56452064197870233)\n",
      "clear session data 49 8049528832\n",
      "5 rewards (0.54846381578947367, -0.42652480106252294)\n",
      "clear session data 49 8049528832\n",
      "6 rewards (0.57728070175438606, -0.34159008626817899)\n",
      "clear session data 49 8049528832\n",
      "7 rewards (0.76967105263157887, -0.53846153846153844)\n",
      "clear session data 49 8049528832\n",
      "8 rewards (0.67671381578947365, -0.42843325366285878)\n",
      "clear session data 49 8049528832\n",
      "9 rewards (0.69389763931888537, -0.42164770105023019)\n",
      "clear session data 49 8049528832\n",
      "0 rewards (0.22793749999999999, -0.63349823887172163)\n",
      "clear session data 49 8049528832\n",
      "1 rewards (0.47618923611111108, -0.6253091203854263)\n",
      "clear session data 49 8049573888\n",
      "2 rewards (0.53749086257309941, -0.58896501727530115)\n",
      "clear session data 49 8049573888\n",
      "3 rewards (0.46786184210526316, -0.4915823856085722)\n",
      "clear session data 49 8049573888\n",
      "4 rewards (0.42813980800653595, -0.49678561673994304)\n",
      "clear session data 49 8049573888\n",
      "5 rewards (0.70478645833333331, -0.49888026996413143)\n",
      "clear session data 49 8049573888\n",
      "6 rewards (0.70502102145682832, -0.53892934810094573)\n",
      "clear session data 49 8049836032\n",
      "7 rewards (0.59620459236326107, -0.50654146498280783)\n",
      "clear session data 49 8049573888\n",
      "8 rewards (0.497953125, -0.44297514951827177)\n",
      "clear session data 49 8049573888\n",
      "9 rewards (0.61678499634502926, -0.35787725628163569)\n"
     ]
    }
   ],
   "source": [
    "for iters, noise in enumerate(3 * [0.0]):\n",
    "    for trial in [300]: \n",
    "        Pretest =  PretrainTest(holes = 0, weight_write = 'weights_cpu/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        weight_read = Pretest.weight\n",
    "        weight_write = 'weights3/rnn_1515tanh512_checkpoint{}_{}'.format(trial, iters)\n",
    "        rewards = Pretest.qlearn(weight_read,  weight_write, iterations = 10, noise = noise, size_train = np.arange(10, 51, 10), size_test=[10, 50],\n",
    "                                feedback = False)\n",
    "        np.save('Rewards_l_{}_{}.npy'.format(iters, trial), rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear session data 49 6336540672\n",
      "0 rewards (0.29999999999999999, -0.59780702584716905)\n",
      "clear session data 49 6648922112\n",
      "1 rewards (0.44556372549019607, -0.61159482075663241)\n",
      "clear session data 49 6649102336\n",
      "2 rewards (0.51536643769349844, -0.53359765322163843)\n",
      "clear session data 49 6649102336\n",
      "3 rewards (0.63846021303258138, -0.41436550825461516)\n",
      "clear session data 49 6649364480\n",
      "4 rewards (0.67616386554621832, -0.55224000247193394)\n",
      "clear session data 49 6649364480\n",
      "5 rewards (0.69410840750773994, -0.53852814676664251)\n",
      "clear session data 49 6649491456\n",
      "6 rewards (0.64686184210526321, -0.49727548498239826)\n",
      "clear session data 49 6649491456\n",
      "7 rewards (0.57871354166666666, -0.47626980649204531)\n",
      "clear session data 49 6649491456\n",
      "8 rewards (0.73286252472480218, -0.48780875684036196)\n",
      "clear session data 49 7132037120\n",
      "9 rewards (0.73577563316993455, -0.4631693428042698)\n",
      "clear session data 49 7132184576\n",
      "0 rewards (0.34815451388888885, -0.58072249902916462)\n",
      "clear session data 49 7132184576\n",
      "1 rewards (0.47261068111455112, -0.4846927072325401)\n",
      "clear session data 49 7132184576\n",
      "2 rewards (0.55624049707602341, -0.56925618267334244)\n",
      "clear session data 49 7132184576\n",
      "3 rewards (0.79428736132610944, -0.58879163526833556)\n",
      "clear session data 49 7132184576\n",
      "4 rewards (0.78671778250773994, -0.45924701436511622)\n",
      "clear session data 49 7132184576\n",
      "5 rewards (0.75833591331269345, -0.48802206475248228)\n",
      "clear session data 49 7132184576\n",
      "6 rewards (0.70692401960784301, -0.40783069608625427)\n",
      "clear session data 49 7132184576\n",
      "7 rewards (0.52751868872549013, -0.35310008481124799)\n",
      "clear session data 49 7173541888\n",
      "8 rewards (0.76248028465772277, -0.37093838507569427)\n",
      "clear session data 49 7173570560\n",
      "9 rewards (0.53781153250773994, -0.37011986862191509)\n",
      "clear session data 49 7173570560\n",
      "0 rewards (0.32000000000000001, -0.65680473372781067)\n",
      "clear session data 49 7173570560\n",
      "1 rewards (0.47779605263157893, -0.50696378823420818)\n",
      "clear session data 49 7173570560\n",
      "2 rewards (0.50789583333333332, -0.51090702354650364)\n",
      "clear session data 49 7173570560\n",
      "3 rewards (0.68467675930021121, -0.35857550266835952)\n",
      "clear session data 49 7173832704\n",
      "4 rewards (0.55929687500000003, -0.38147282579266162)\n",
      "clear session data 49 7173832704\n",
      "5 rewards (0.73439307598039216, -0.44649733841548933)\n",
      "clear session data 49 7173832704\n",
      "6 rewards (0.83895614035087718, -0.44472684146092634)\n",
      "clear session data 49 7173832704\n",
      "7 rewards (0.86743351715686279, -0.35072509269337454)\n",
      "clear session data 49 7173832704\n",
      "8 rewards (0.8633888766032729, -0.36971155453092186)\n",
      "clear session data 49 7173877760\n",
      "9 rewards (0.7367586805555556, -0.30596037462894821)\n"
     ]
    }
   ],
   "source": [
    "for iters, noise in enumerate(3 * [0.0]):\n",
    "    for trial in [399]: \n",
    "        Pretest =  PretrainTest(holes = 0, weight_write = 'weights_cpu/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        weight_read = Pretest.weight\n",
    "        weight_write = 'weights2/rnn_1515tanh512_checkpoint{}_{}'.format(trial, iters)\n",
    "        rewards = Pretest.qlearn(weight_read,  weight_write, iterations = 10, noise = noise, size_train = np.arange(10, 51, 10), size_test=[10, 50],\n",
    "                                feedback = False)\n",
    "        np.save('Rewards_l_{}_{}.npy'.format(iters, trial), rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear session data 49 6358327296\n",
      "0 rewards (0.3182799369747899, -0.69377767321571238)\n",
      "clear session data 49 6358470656\n",
      "1 rewards (0.67640241228070175, -0.68422671553217984)\n",
      "clear session data 49 6358470656\n",
      "2 rewards (0.75446308479532165, -0.46487841716847861)\n",
      "clear session data 49 6358732800\n",
      "3 rewards (0.77596226780185762, -0.44118198931740588)\n",
      "clear session data 49 6358732800\n",
      "4 rewards (0.91808114035087718, -0.50960775940950409)\n",
      "clear session data 49 6358732800\n",
      "5 rewards (0.9479375000000001, -0.51510765220442645)\n",
      "clear session data 49 6358732800\n",
      "6 rewards (0.90664338235294117, -0.32291001693219934)\n",
      "clear session data 49 6358732800\n",
      "7 rewards (0.83445540935672513, -0.50979062323288726)\n",
      "clear session data 49 7493226496\n",
      "8 rewards (0.6381944444444444, -0.3444359691082477)\n",
      "clear session data 49 7493398528\n",
      "9 rewards (0.8657156862745099, -0.47204367314002516)\n",
      "clear session data 49 7493398528\n",
      "0 rewards (0.44805555555555554, -0.7174244240016916)\n",
      "clear session data 49 7534702592\n",
      "1 rewards (0.7084595588235294, -0.7165702886856733)\n",
      "clear session data 49 7534964736\n",
      "2 rewards (0.88723944358445128, -0.52319334917440696)\n",
      "clear session data 49 8679292928\n",
      "3 rewards (0.79868229166666671, -0.45983956416601451)\n",
      "clear session data 49 8679346176\n",
      "4 rewards (0.76668633900928795, -0.55146223678504669)\n",
      "clear session data 49 8679350272\n",
      "5 rewards (0.8492757352941176, -0.43311496196111587)\n",
      "clear session data 49 8679477248\n",
      "6 rewards (0.70999999999999996, -0.48254122078624151)\n",
      "clear session data 49 8679477248\n",
      "7 rewards (0.71613854489164086, -0.53915631202811709)\n",
      "clear session data 49 8679477248\n",
      "8 rewards (0.82639008059364083, -0.49204103043714575)\n",
      "clear session data 49 8679477248\n",
      "9 rewards (0.66652192982456138, -0.52771088482179718)\n",
      "clear session data 49 8679477248\n",
      "0 rewards (0.33695981682146542, -0.65523289429567444)\n",
      "clear session data 49 8679567360\n",
      "1 rewards (0.66716132779866333, -0.61003144484202898)\n",
      "clear session data 49 8679567360\n",
      "2 rewards (0.84646710526315783, -0.73969726854342244)\n",
      "clear session data 49 8679567360\n",
      "3 rewards (0.7785614035087719, -0.62130177514792906)\n",
      "clear session data 49 8679567360\n",
      "4 rewards (0.95681270424836595, -0.71597633136094674)\n",
      "clear session data 49 8679567360\n",
      "5 rewards (0.90768382352941179, -0.65843052299230098)\n",
      "clear session data 49 8679567360\n",
      "6 rewards (0.82854983660130721, -0.47381562645854891)\n",
      "clear session data 49 8679567360\n",
      "7 rewards (0.92457410990712074, -0.46153846153846156)\n",
      "clear session data 49 8679567360\n",
      "8 rewards (0.88560737014103896, -0.62847818369189379)\n",
      "clear session data 49 8679567360\n",
      "9 rewards (0.82476096491228068, -0.10813908386896595)\n"
     ]
    }
   ],
   "source": [
    "for iters, noise in enumerate(3 * [0.0]):\n",
    "    for trial in [270]: \n",
    "        Pretest =  PretrainTest(holes = 0, weight_write = 'weights_cpu/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        weight_read = Pretest.weight\n",
    "        weight_write = 'weights2/rnn_1515tanh512_checkpoint{}_{}'.format(trial, iters)\n",
    "        rewards = Pretest.qlearn(weight_read,  weight_write, iterations = 10, noise = noise, size_train = np.arange(10, 51, 10), size_test=[10, 50])\n",
    "        np.save('Rewards_l_{}_{}.npy'.format(iters, trial), rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear session data 49 6543319040\n",
      "0 rewards (0.43925438596491229, -0.69822485207100593)\n",
      "clear session data 49 6564122624\n",
      "1 rewards (0.71158662280701745, -0.46846289699311677)\n",
      "clear session data 49 6564208640\n",
      "2 rewards (0.86667187499999998, -0.64572938114052181)\n",
      "clear session data 49 7280594944\n",
      "3 rewards (0.84938439849624059, -0.42696800984595273)\n",
      "clear session data 49 7808577536\n",
      "4 rewards (0.8274565972222222, -0.41073194872214069)\n",
      "clear session data 49 7808839680\n",
      "5 rewards (0.80727685328517373, -0.5305652704539352)\n",
      "clear session data 49 7808839680\n",
      "6 rewards (0.61908333333333332, -0.56386794203067758)\n",
      "clear session data 49 7808839680\n",
      "7 rewards (0.90784874871001031, -0.59784116124260356)\n",
      "clear session data 49 8268136448\n",
      "8 rewards (0.86873132586367885, -0.62252964259711896)\n",
      "clear session data 49 8268402688\n",
      "9 rewards (0.88723501461988308, -0.39379306179868145)\n",
      "clear session data 49 8268402688\n",
      "10 rewards (0.78858726780185762, -0.49511417228353005)\n",
      "clear session data 49 8268402688\n",
      "11 rewards (0.79546600877192986, -0.48282619613783173)\n",
      "clear session data 49 8268402688\n",
      "12 rewards (0.876735745614035, -0.5681397928994083)\n",
      "clear session data 49 8268402688\n",
      "13 rewards (0.72677310995248301, -0.57424375075473977)\n",
      "clear session data 49 8832860160\n",
      "14 rewards (0.60912326388888893, -0.5079163228204493)\n",
      "clear session data 49 8832921600\n",
      "15 rewards (0.86405923202614376, -0.58175683136047529)\n",
      "clear session data 49 8833183744\n",
      "16 rewards (0.59705678104575166, -0.39239587635486783)\n",
      "clear session data 49 8833183744\n",
      "17 rewards (0.85852941176470587, -0.44663963651555649)\n",
      "clear session data 49 8833183744\n",
      "18 rewards (0.51000000000000001, -0.56423158813065433)\n",
      "clear session data 49 8833183744\n",
      "19 rewards (0.59881249999999997, -0.52523873596459825)\n",
      "clear session data 49 8833183744\n",
      "0 rewards (0.099464285714285713, -0.70414201183431957)\n",
      "clear session data 49 8833183744\n",
      "1 rewards (0.12927631578947368, -0.79881656804733736)\n",
      "clear session data 49 8833183744\n",
      "2 rewards (0.57830183531746027, -0.66331712250288355)\n",
      "clear session data 49 8833183744\n",
      "3 rewards (0.80854166666666671, -0.53846153846153844)\n",
      "clear session data 49 8833183744\n",
      "4 rewards (0.91392361111111109, -0.45046838193593308)\n",
      "clear session data 49 8833183744\n",
      "5 rewards (0.98780357142857134, -0.6046287071178601)\n",
      "clear session data 49 8833183744\n",
      "6 rewards (0.6789670138888888, -0.41510812846401179)\n",
      "clear session data 49 8833183744\n",
      "7 rewards (0.74637387539361222, -0.39787612210669893)\n",
      "clear session data 49 8833183744\n",
      "8 rewards (0.72698412698412695, -0.31738345314242822)\n",
      "clear session data 49 8833183744\n",
      "9 rewards (0.85661036706349214, -0.46701489455817802)\n",
      "clear session data 49 8833183744\n",
      "10 rewards (0.91896825396825399, -0.47719828786999369)\n"
     ]
    }
   ],
   "source": [
    "for iters, noise in enumerate(3 * [0.0]):\n",
    "    for trial in [227]: \n",
    "        Pretest =  PretrainTest(holes = 0, weight_write = 'weights_cpu/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        weight_read = Pretest.weight\n",
    "        weight_write = 'weights2/rnn_1515tanh512_checkpoint{}_{}'.format(trial, iters)\n",
    "        rewards = Pretest.qlearn(weight_read,  weight_write, iterations = 20, noise = noise, size_train = np.arange(10, 51, 10), size_test=[10, 50])\n",
    "        np.save('Rewards_l_{}_{}.npy'.format(iters, trial), rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear session data 49 5638848512\n",
      "0 rewards (0.27656857287449393, -0.69822485207100593)\n",
      "clear session data 49 5910835200\n",
      "1 rewards (0.34825694444444444, -0.59767087308296096)\n",
      "clear session data 49 6034640896\n",
      "2 rewards (0.61948529411764708, -0.67455621301775148)\n",
      "clear session data 49 6774509568\n",
      "3 rewards (0.82756733746130029, -0.62243431304097496)\n",
      "clear session data 49 6774636544\n",
      "4 rewards (0.74804464285714289, -0.48595968799095357)\n",
      "clear session data 49 6774636544\n",
      "5 rewards (0.80730636717406257, -0.45013116842107748)\n",
      "clear session data 49 6774636544\n",
      "6 rewards (0.55521300186741362, -0.53578636663545254)\n",
      "clear session data 49 6774898688\n",
      "7 rewards (0.55835416666666671, -0.26786958822598644)\n",
      "clear session data 49 6774636544\n",
      "8 rewards (0.69591431704260653, -0.61143181156578152)\n",
      "clear session data 49 8586153984\n",
      "9 rewards (0.44770673076923079, -0.39762537758099886)\n",
      "clear session data 49 8586235904\n",
      "10 rewards (0.82702205882352942, -0.57574263343494114)\n",
      "clear session data 49 8586235904\n",
      "11 rewards (0.96991071428571429, -0.52145026781524484)\n",
      "clear session data 49 8586235904\n",
      "12 rewards (0.84840401785714281, -0.35178986400300799)\n",
      "clear session data 49 8586235904\n",
      "13 rewards (0.89720102339181285, -0.71607248520710054)\n",
      "clear session data 49 8586235904\n",
      "14 rewards (0.93730133928571435, -0.5927117203051695)\n",
      "clear session data 49 8688959488\n",
      "15 rewards (0.72975000000000001, -0.4865810771294895)\n",
      "clear session data 49 8689020928\n",
      "16 rewards (0.54693530701754389, -0.50337586474163598)\n",
      "clear session data 49 8689020928\n",
      "17 rewards (0.70725804093567257, -0.53932775958016343)\n",
      "clear session data 49 8689102848\n",
      "18 rewards (0.69503298611111108, -0.39798912678130866)\n",
      "clear session data 49 8689102848\n",
      "19 rewards (0.72951923076923086, -0.39059967063641698)\n",
      "clear session data 49 8689102848\n",
      "0 rewards (0.23435763888888889, -0.64072181735937539)\n",
      "clear session data 49 8689102848\n",
      "1 rewards (0.35893229166666668, -0.78106508875739644)\n",
      "clear session data 49 8689102848\n",
      "2 rewards (0.74801215277777777, -0.70414201183431957)\n",
      "clear session data 49 8689102848\n",
      "3 rewards (0.76624382954936354, -0.72781065088757391)\n",
      "clear session data 49 8689102848\n",
      "4 rewards (0.91600238813474111, -0.69822485207100593)\n",
      "clear session data 49 8689102848\n",
      "5 rewards (0.7551909722222222, -0.63396094137852388)\n",
      "clear session data 49 8689102848\n",
      "6 rewards (0.84466913377192987, -0.59181283460129619)\n",
      "clear session data 49 8689364992\n",
      "7 rewards (0.75541021671826636, -0.34661914893922974)\n",
      "clear session data 49 8689102848\n",
      "8 rewards (0.7375677083333334, -0.59268088921004547)\n",
      "clear session data 49 8689102848\n",
      "9 rewards (0.6280065359477125, -0.67476611226611227)\n",
      "clear session data 49 8689102848\n",
      "10 rewards (0.55688357843137259, -0.50704593781030627)\n",
      "clear session data 49 8689364992\n",
      "11 rewards (0.78786038011695902, -0.49978128815116096)\n",
      "clear session data 49 8689364992\n",
      "12 rewards (0.74468485552115582, -0.36945530634947943)\n",
      "clear session data 49 8689364992\n",
      "13 rewards (0.84645375386996913, -0.57806070430536249)\n",
      "clear session data 49 8689364992\n",
      "14 rewards (0.95893055555555551, -0.60457105084508933)\n",
      "clear session data 49 8689364992\n",
      "15 rewards (0.91803485576923083, -0.54716384953760899)\n",
      "clear session data 49 8689364992\n",
      "16 rewards (0.75698805147058823, -0.55266327428724127)\n",
      "clear session data 49 8689364992\n",
      "17 rewards (0.51848684210526319, -0.27389268049794557)\n",
      "clear session data 49 8689364992\n",
      "18 rewards (0.57882352941176474, -0.35149047240562847)\n",
      "clear session data 49 8689364992\n",
      "19 rewards (0.59551096491228073, -0.51536722321606043)\n",
      "clear session data 49 8689364992\n",
      "0 rewards (0.46739362422600617, -0.66272189349112431)\n",
      "clear session data 49 8689627136\n",
      "1 rewards (-0.13, -0.78106508875739644)\n",
      "clear session data 49 8689627136\n",
      "2 rewards (0.16999999999999998, -0.78106508875739644)\n",
      "clear session data 49 8689627136\n",
      "3 rewards (0.48941666666666667, -0.64135537949092036)\n",
      "clear session data 49 8689627136\n",
      "4 rewards (0.8534778766769866, -0.74042426183313093)\n",
      "clear session data 49 8689627136\n",
      "5 rewards (0.58558808479532165, -0.52098931288491723)\n",
      "clear session data 49 8689627136\n",
      "6 rewards (0.56813888888888897, -0.43876452297723906)\n",
      "clear session data 49 8689627136\n",
      "7 rewards (0.90849671052631575, -0.38498442724999027)\n",
      "clear session data 49 8689627136\n",
      "8 rewards (0.92796308479532175, -0.43666592766359358)\n",
      "clear session data 49 8689627136\n",
      "9 rewards (0.878531798245614, -0.39686959483081174)\n",
      "clear session data 49 8689627136\n",
      "10 rewards (0.63788715277777774, -0.51682475715031839)\n",
      "clear session data 49 8689627136\n",
      "11 rewards (0.94293822024423801, -0.69230769230769229)\n",
      "clear session data 49 8778022912\n",
      "12 rewards (0.84377173632610947, -0.38806581363103554)\n",
      "clear session data 49 8778166272\n",
      "13 rewards (0.80791425254312255, -0.39682123574759159)\n",
      "clear session data 49 8778166272\n",
      "14 rewards (0.67557419590643275, -0.39995154303759839)\n",
      "clear session data 49 8778166272\n",
      "15 rewards (0.97776315789473678, -0.67070309513890869)\n",
      "clear session data 49 8778166272\n",
      "16 rewards (0.78841212406015027, -0.50524096357817916)\n",
      "clear session data 49 8778166272\n",
      "17 rewards (0.81358408582731334, -0.41184003818863085)\n",
      "clear session data 49 8778166272\n",
      "18 rewards (0.60752604166666657, -0.49774625826662022)\n",
      "clear session data 49 8778166272\n",
      "19 rewards (0.78146611089611284, -0.40239305035953582)\n"
     ]
    }
   ],
   "source": [
    "for iters, noise in enumerate(3 * [0.0]):\n",
    "    for trial in [227]: \n",
    "        Pretest =  PretrainTest(holes = 0, weight_write = 'weights_cpu/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        weight_read = Pretest.weight\n",
    "        weight_write = 'weights2/rnn_1515tanh512_checkpoint{}_{}'.format(trial, iters+2)\n",
    "        rewards = Pretest.qlearn(weight_read,  weight_write, iterations = 20, noise = noise, size_train = np.arange(10, 51, 10), size_test=[10, 50])\n",
    "        np.save('Rewards_l_{}_{}.npy'.format(iters, trial), rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear session data 49 6293172224\n",
      "0 rewards (0.71299821551427589, -0.69936249879811752)\n",
      "clear session data 49 6313897984\n",
      "1 rewards (0.54328216911764704, -0.41944367824770867)\n",
      "clear session data 49 6314074112\n",
      "2 rewards (0.80235689714482283, -0.16131549072524365)\n",
      "clear session data 49 6314201088\n",
      "3 rewards (0.66447743055555564, -0.56424212210577163)\n",
      "clear session data 49 6314201088\n",
      "4 rewards (0.89153143274853797, -0.43317127715902021)\n"
     ]
    }
   ],
   "source": [
    "for iters, noise in enumerate(3 * [0.0]):\n",
    "    for trial in [204]: \n",
    "        Pretest =  PretrainTest(holes = 0, weight_write = 'weights_cpu/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        weight_read = Pretest.weight\n",
    "        weight_write = 'weights2/rnn_1515tanh512_checkpoint{}_{}'.format(trial, iters+2)\n",
    "        rewards = Pretest.qlearn(weight_read,  weight_write, iterations = 20, noise = noise, size_train = np.arange(10, 51, 10), size_test=[10, 50])\n",
    "        np.save('Rewards_l_{}_{}.npy'.format(iters, trial), rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "759px",
    "left": "0px",
    "right": "1228px",
    "top": "67px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
