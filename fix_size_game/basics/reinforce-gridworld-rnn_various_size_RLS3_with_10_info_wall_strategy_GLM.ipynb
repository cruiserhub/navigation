{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#quick-start\" data-toc-modified-id=\"quick-start-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>quick start</a></span><ul class=\"toc-item\"><li><span><a href=\"#Resources\" data-toc-modified-id=\"Resources-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Resources</a></span></li></ul></li><li><span><a href=\"#FULL-MODEL\" data-toc-modified-id=\"FULL-MODEL-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>FULL MODEL</a></span><ul class=\"toc-item\"><li><span><a href=\"#Packages\" data-toc-modified-id=\"Packages-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Packages</a></span><ul class=\"toc-item\"><li><span><a href=\"#Qnetwork\" data-toc-modified-id=\"Qnetwork-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Qnetwork</a></span></li></ul></li><li><span><a href=\"#POMDP-RNN-Game\" data-toc-modified-id=\"POMDP-RNN-Game-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>POMDP RNN Game</a></span></li><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Results</a></span><ul class=\"toc-item\"><li><span><a href=\"#Standard-setting：-grid-=--(3,7)，-holes-=-0\" data-toc-modified-id=\"Standard-setting：-grid-=--(3,7)，-holes-=-0-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Standard setting： grid =  (3,7)， holes = 0</a></span></li><li><span><a href=\"#Model-Tranining\" data-toc-modified-id=\"Model-Tranining-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Model Tranining</a></span></li><li><span><a href=\"#decoding-vs-performance\" data-toc-modified-id=\"decoding-vs-performance-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>decoding vs performance</a></span></li><li><span><a href=\"#learning-rate-vs-performance\" data-toc-modified-id=\"learning-rate-vs-performance-2.3.4\"><span class=\"toc-item-num\">2.3.4&nbsp;&nbsp;</span>learning rate vs performance</a></span></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-2.3.5\"><span class=\"toc-item-num\">2.3.5&nbsp;&nbsp;</span>Summary</a></span></li><li><span><a href=\"#Anlytic-part-,-check-the-behaviour-correspond-to-each-decoding-level-and-explain-why\" data-toc-modified-id=\"Anlytic-part-,-check-the-behaviour-correspond-to-each-decoding-level-and-explain-why-2.3.6\"><span class=\"toc-item-num\">2.3.6&nbsp;&nbsp;</span>Anlytic part , check the behaviour correspond to each decoding level and explain why</a></span></li></ul></li><li><span><a href=\"#PCA\" data-toc-modified-id=\"PCA-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>PCA</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quick start "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check relation betweeen dynamics and generalization.   Hypothesis to make: generalization can only be understood in level of joint dynamical system, there is a clear link between the two**\n",
    "\n",
    "**Dynamnics determines generalization , not decoding , same decoding level can have very different dynamics , thus different generalization level.  Only when the dynamics of RNN forms object correspond to real relevant objects for game, the generalization can be good.   For instance , in a varying size game, you extend the size of game from 10 to 30, what will happen?  You can do a kind of dynamical programing , according to which wall you have seen and how many steps you have passed , you decide future action.    This can be achieved robustly by the dynamical system where fix points are correspond to walls**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "* [*The* Reinforcement learning book from Sutton & Barto](http://incompleteideas.net/sutton/book/the-book-2nd.html)\n",
    "* [The REINFORCE paper from Ronald J. Williams (1992)](http://www-anw.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tie/anaconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import init\n",
    "from torch.nn import DataParallel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML\n",
    "\n",
    "import pretrain\n",
    "from pretrain import *\n",
    "\n",
    "import navigation2\n",
    "from navigation2 import *\n",
    "\n",
    "import Nets \n",
    "from Nets import *\n",
    "\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "%pylab inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the liquid state approach to work, you need a lot of neurons as surplus or enough hidden to hidden connectivity to make it have an effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the relation to head direction, this order kept in limit cycle**\n",
    "**Could we define the order parameter for behaviour and link it to dynamics?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The GLM analysis of variance for different variables\n",
    "The features include x, y, sensory,  action, last click memory , last twice click memory, the last twice click has a very strong contribution to features, but it inludes the last one click. In a sense, the integrated memory is not equalling to memroy 1 plus memory2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the stimulus memory(status) and action base for memory and navigation  \n",
    "def Transform(States, Poss, Hiddens, Actions, Context, history = False, size = 15):\n",
    "    # last click state\n",
    "    Status = np.concatenate([State_transform(state, poss, size) for state, poss in zip(States, Poss)])\n",
    "    Hiddens = np.concatenate(Hiddens)\n",
    "    Poss = np.concatenate(Poss)\n",
    "    Actions = np.concatenate(Actions)\n",
    "    Context = np.concatenate(Context)\n",
    "    # transform state to stim　\n",
    "    States = np.concatenate(States)\n",
    "    # transform status to memory\n",
    "    Memory = history_summary(Status)\n",
    "    set_ = set([tuple(s) for s in States])\n",
    "    dict_ = {}\n",
    "    for i, s in enumerate(set_): \n",
    "        dict_.update({s:i})\n",
    "    Stim = [dict_[tuple(s)] for s in States] \n",
    "    set_ = set([tuple(m) for m in Memory])\n",
    "#     dict_ = {}\n",
    "#     for i, m in enumerate(set_): \n",
    "#         dict_.update({m:i})\n",
    "#     Mem = [dict_[tuple(m)] for m in Memory] \n",
    "    if history == False:\n",
    "        return States, Poss, Hiddens, Actions, Status, Context\n",
    "    else:\n",
    "        return States, Poss, Hiddens, Actions, Status, Context, Memory \n",
    "\n",
    "\n",
    "# histroy memory of two \n",
    "def history_summary(Status):\n",
    "#     S = [p[0]  for s, p in zip(State, Poss)]\n",
    "    M = np.zeros((len(Status), 2))\n",
    "    m2 = 0\n",
    "    for i, (s1, s2) in enumerate(zip(Status[:-1], Status[1:])): \n",
    "        # if next clicks changes, then store this click as a memory value registed in m2  \n",
    "        if s2 != s1:\n",
    "            m2 = s1\n",
    "        # sore memory,  m0 as memory of stimulus, m1 as memory of second click    \n",
    "        M[i+1, 0] = s2\n",
    "        M[i+1, 1] = m2   \n",
    "#         print (s1)\n",
    "    return M  \n",
    "# State_transform()\n",
    "\n",
    "# def Transform(States, Poss, Hiddens, Actions, Context):\n",
    "#     Status = np.concatenate([State_transform(state, poss) for state, poss in zip(States, Poss)])\n",
    "#     Hiddens = np.concatenate(Hiddens)\n",
    "#     Poss = np.concatenate(Poss)\n",
    "#     Actions = np.concatenate(Actions)\n",
    "#     Context = np.concatenate(Context)\n",
    "#     # transform state to stim　\n",
    "#     States = np.concatenate(States)\n",
    "#     return States, Poss, Hiddens, Actions, Status, Context\n",
    "\n",
    "# transform to time section\n",
    "def Stage_transform(State):\n",
    "    S = np.cumsum([np.sum(s1 != s2) for (s1, s2) in zip(State[:-1], State[1:])] + [1]) \n",
    "    return S\n",
    "\n",
    "# transform to space section\n",
    "def wall_detection(pos, size):\n",
    "    if pos[0] == 2:\n",
    "        Stim = 1\n",
    "    elif pos[0] == 2 + size - 1:\n",
    "        Stim = 2\n",
    "    elif pos[1] == 2:\n",
    "        Stim = 3\n",
    "    elif pos[1] == 2 + size - 1:\n",
    "        Stim = 4\n",
    "    else:\n",
    "        Stim = 0 \n",
    "    return Stim \n",
    "# for the memory feature, a Msimple one is just the last click, a most complicate one should be click sequence     \n",
    "def State_transform(State, Poss, size):\n",
    "#     S = [p[0]  for s, p in zip(State, Poss)]\n",
    "    S = [wall_detection(pos, size) for pos in Poss]\n",
    "    Status = []\n",
    "    s1 = 0\n",
    "    for s in S: \n",
    "        if s != 0: \n",
    "            s1 = s\n",
    "#         print (s1)\n",
    "        Status.append(s1)\n",
    "    return Status\n",
    "# histroy memory of two \n",
    "def history_summary(Status):\n",
    "#     S = [p[0]  for s, p in zip(State, Poss)]\n",
    "    M = np.zeros((len(Status), 2))\n",
    "    m2 = 0\n",
    "    for i, (s1, s2) in enumerate(zip(Status[:-1], Status[1:])): \n",
    "        # if next clicks changes, then store this click as a memory value registed in m2  \n",
    "        if s2 != s1:\n",
    "            m2 = s1\n",
    "        # sore memory,  m0 as memory of stimulus, m1 as memory of second click    \n",
    "        M[i+1, 0] = s2\n",
    "        M[i+1, 1] = m2   \n",
    "#         print (s1)\n",
    "    return M\n",
    "\n",
    "def Feature_preprocessing(States, Poss, Hiddens, Actions, Context, size = 15):\n",
    "    States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context)\n",
    "    x =  Hiddens[:, :512]\n",
    "    z = (x - np.min(x))/(np.max(x) - np.min(x))\n",
    "    y = np.log(z/(1-z + 1e-3) + 1e-3)\n",
    "    A = np.array([np.eye(4)[a] for a in Actions]).reshape(-1, 4)\n",
    "    Y = np.array([np.eye(size)[y] for y in Poss[:,0] -2]).reshape(-1, size)\n",
    "    X = np.array([np.eye(size)[x] for x in Poss[:,1] - 2]).reshape(-1, size)\n",
    "    M = np.array([np.eye(5)[s] for s in Status]).reshape(-1, 5)\n",
    "    S = States.reshape(-1, 9)\n",
    "    C = np.array(Context).reshape(-1, 1)\n",
    "    # S_wall = np.array([np.eye(27)[s] for s in Stim_wall]).reshape(-1, 27)\n",
    "    Features = np.concatenate((A, Y, X, M, S, C), axis = 1)\n",
    "    Features_A = np.concatenate((Y, X, M, S, C), axis = 1)\n",
    "    Features_Y = np.concatenate((A, X, M, S, C), axis = 1)\n",
    "    Features_X = np.concatenate((A, Y, M, S, C), axis = 1)\n",
    "    Features_M = np.concatenate((A, Y, X, S, C), axis = 1)\n",
    "    Features_S = np.concatenate((A, Y, X, M, C), axis = 1)\n",
    "    Features_C = np.concatenate((A, Y, X, M, S), axis = 1)\n",
    "    return y, Features, Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C\n",
    "# State_transform()\n",
    "\n",
    "# record sessions 100 for 2 different context, record the relevant variables \n",
    "def Data_record(weight, k_action = 1, epsilon = 0, size = 15, T = 500, seed_num = 1e3):\n",
    "    PC_traces = []\n",
    "    Hiddens = []\n",
    "    Poss = []\n",
    "    Actions = []\n",
    "    States = []\n",
    "    Context = []\n",
    "    for i in range(T):\n",
    "        torch.manual_seed(np.random.randint(seed_num))\n",
    "        hidden0 = torch.randn(1, 512)\n",
    "        c  = np.random.randint(2)\n",
    "        start = (np.random.randint(2, size +2),  np.random.randint(2, size+2))\n",
    "        game = ValueMaxGame(grid_size = (size, size), holes = 0, random_seed = 0 , set_reward = [(0.5, 0.25), (0.5, 0.75)], input_type = 0, discount = 0.9, alpha = 1\n",
    "                           ,lam = 0)\n",
    "        game.net.load_state_dict(torch.load(weight))\n",
    "        game.net.k_action = k_action \n",
    "        grid = game.grid.grid.copy()\n",
    "        Pos, hidden, dh, Action, State, reward = trajectory(game, start, reward_control = c, size = size, \\\n",
    "                                                                  test = 0, limit_set = 4, init_hidden = False, hidden = hidden0, epsilon = epsilon)\n",
    "        Hiddens.append(hidden)\n",
    "        Poss.append(Pos[1:])\n",
    "        Actions.append(Action)\n",
    "        States.append(State)\n",
    "        Context.append(c * np.ones(len(State)))\n",
    "    return States, Poss, Hiddens, Actions, Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Echo Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variance 0.5336270047635198 0.5258583598207048\n",
      "total variance 0.003018779304621577 0.002366118268337725\n",
      "total variance 0.0017804987600531508 0.0011223110994322161\n",
      "total variance 0.005911400432568614 0.004308591821884522\n",
      "total variance 0.014671318078486161 0.014159507630620193\n",
      "total variance 0.05374836020304648 0.05420942217596281\n",
      "total variance 0.03954487925305729 0.04008925433572226\n"
     ]
    }
   ],
   "source": [
    "# record sessions 100 for 2 different context, record the relevant variables \n",
    "weight ='weights_fix/weights1/rnn_1515tanh512_checkpoint0_2_0'\n",
    "States1, Poss1, Hiddens1, Actions1, Context1 = Data_record(weight)\n",
    "y, Features, Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C = Feature_preprocessing(States1, Poss1, Hiddens1, Actions1,\\\n",
    "                                                                                                           Context1)\n",
    "clf = Lasso(alpha = 1e-3)\n",
    "cv_scores_all = cross_validate(clf, Features, y, cv = 5, scoring=('r2'), return_train_score = True)\n",
    "print ('total variance', np.mean(cv_scores_all['train_score']), np.mean(cv_scores_all['test_score']))\n",
    "importances = []\n",
    "importances_std = []\n",
    "for i, feature in enumerate([Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C]):\n",
    "    clf = Lasso(alpha = 1e-3)\n",
    "    cv_scores = cross_validate(clf, feature, y, cv = 5, scoring=('r2'), return_train_score = True)\n",
    "    print ('total variance', np.mean(cv_scores_all['train_score'] -  cv_scores['train_score']), \\\n",
    "           np.mean(cv_scores_all['test_score'] - cv_scores['test_score']))\n",
    "    importances.append(np.mean(cv_scores_all['test_score'] - cv_scores['test_score']))\n",
    "    importances_std.append(np.std(cv_scores_all['test_score'] - cv_scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('importance_echo_early', importances)\n",
    "np.save('importance_echo_early_std', importances_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x7f96a2395320>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a2701630>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a1bcee80>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a23ef4a8>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a1cfd588>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a1cfdc18>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a1d1c2e8>],\n",
       " <a list of 7 Text yticklabel objects>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEDCAYAAADA9vgDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96a22df6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 009\n",
    "ax = subplot(1, 1, 1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "imp = np.load('importance_echo_early.npy')\n",
    "imp_std = np.load('importance_echo_early_std.npy')\n",
    "plt.bar(np.arange(6), height = imp, yerr = imp_std)\n",
    "plt.xticks([0, 1, 2, 3, 4, 5], ['A', 'Y', 'X', 'M', 'S', 'C'], size = 15)\n",
    "plt.yticks([0, 0, 0.02, 0.04, 0.06, 0.08, 0.1], size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variance 0.3900987683273135 0.3734116620426762\n",
      "total variance 0.007412913894201567 0.006524081372758017\n",
      "total variance 0.00871587652987571 0.003744449241153458\n",
      "total variance 0.019627994153965954 0.017682182678894633\n",
      "total variance 0.03783858737817891 0.03711714335277766\n",
      "total variance 0.05536294711007096 0.056180287701844675\n",
      "total variance 0.008143078767178147 0.007955799192881752\n"
     ]
    }
   ],
   "source": [
    "# record sessions 100 for 2 different context, record the relevant variables \n",
    "# record sessions 100 for 2 different context, record the relevant variables \n",
    "weight ='weights_fix/weights1/rnn_1515tanh512_checkpoint0_2_9'\n",
    "States1, Poss1, Hiddens1, Actions1, Context1 = Data_record(weight)\n",
    "y, Features, Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C = Feature_preprocessing(States1, Poss1, Hiddens1, Actions1,\\\n",
    "                                                                                                           Context1)\n",
    "clf = Lasso(alpha = 1e-3)\n",
    "cv_scores_all = cross_validate(clf, Features, y, cv = 5, scoring=('r2'), return_train_score = True)\n",
    "print ('total variance', np.mean(cv_scores_all['train_score']), np.mean(cv_scores_all['test_score']))\n",
    "importances = []\n",
    "importances_std = []\n",
    "for i, feature in enumerate([Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C]):\n",
    "    clf = Lasso(alpha = 1e-3)\n",
    "    cv_scores = cross_validate(clf, feature, y, cv = 5, scoring=('r2'), return_train_score = True)\n",
    "    print ('total variance', np.mean(cv_scores_all['train_score'] -  cv_scores['train_score']), \\\n",
    "           np.mean(cv_scores_all['test_score'] - cv_scores['test_score']))\n",
    "    importances.append(np.mean(cv_scores_all['test_score'] - cv_scores['test_score']))\n",
    "    importances_std.append(np.std(cv_scores_all['test_score'] - cv_scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('importance_echo', importances)\n",
    "np.save('importance_echo_std', importances_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x7f96a0e64128>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a0e641d0>],\n",
       " <a list of 2 Text yticklabel objects>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEDCAYAAADdpATdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96a0e18400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 009\n",
    "ax = subplot(1, 1, 1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "imp = np.load('importance_echo.npy')\n",
    "imp_std = np.load('importance_echo_std.npy')\n",
    "plt.bar(np.arange(6), height = imp, yerr = imp_std)\n",
    "plt.xticks([0, 1, 2, 3, 4, 5], ['A', 'Y', 'X', 'M', 'S', 'C'], size = 15)\n",
    "plt.yticks([0, 0.1], size = 15)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variance 0.48573512471582847 0.4760540102841452\n",
      "total variance 0.006462179396043999 0.005937664058737535\n",
      "total variance 0.017844784688296467 0.01568026495057735\n",
      "total variance 0.0137360988308718 0.012141880430233131\n",
      "total variance 0.19824898015596476 0.20164431620665604\n",
      "total variance 0.07569310612763996 0.07648974476504691\n",
      "total variance 0.02935466421408215 0.02974562872647508\n"
     ]
    }
   ],
   "source": [
    "weight0 ='weights_cpu1/rnn_1515tanh512_checkpoint39'\n",
    "States1, Poss1, Hiddens1, Actions1, Context1 = Data_record(weight, epsilon=0)\n",
    "y, Features, Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C = Feature_preprocessing(States1, Poss1, Hiddens1, Actions1,\\\n",
    "                                                                                                           Context1)\n",
    "clf = Lasso(alpha = 1e-3)\n",
    "cv_scores_all = cross_validate(clf, Features, y, cv = 5, scoring=('r2'), return_train_score = True)\n",
    "print ('total variance', np.mean(cv_scores_all['train_score']), np.mean(cv_scores_all['test_score']))\n",
    "importances = []\n",
    "importances_std = []\n",
    "for i, feature in enumerate([Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C]):\n",
    "    clf = Lasso(alpha = 1e-3)\n",
    "    cv_scores = cross_validate(clf, feature, y, cv = 5, scoring=('r2'), return_train_score = True)\n",
    "    print ('total variance', np.mean(cv_scores_all['train_score'] -  cv_scores['train_score']), \\\n",
    "           np.mean(cv_scores_all['test_score'] - cv_scores['test_score']))\n",
    "    importances.append(np.mean(cv_scores_all['test_score'] - cv_scores['test_score']))\n",
    "    importances_std.append(np.std(cv_scores_all['test_score'] - cv_scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variance 0.6199333086024569 0.616098696369416\n",
      "total variance 0.0002084292386299813 0.00017799360267927166\n",
      "total variance 0.005637816634458548 0.005200699670664855\n",
      "total variance 0.003856031573089469 0.00349963747524884\n",
      "total variance 0.24456735652920597 0.25001901446643426\n",
      "total variance 0.08419576398176423 0.08454351574639349\n",
      "total variance 0.03750032346686545 0.03856816138832022\n"
     ]
    }
   ],
   "source": [
    "weight0 ='weights_cpu1/rnn_1515tanh512_checkpoint39'\n",
    "States1, Poss1, Hiddens1, Actions1, Context1 = Data_record(weight, epsilon=1)\n",
    "y, Features, Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C = Feature_preprocessing(States1, Poss1, Hiddens1, Actions1,\\\n",
    "                                                                                                           Context1)\n",
    "clf = Lasso(alpha = 1e-3)\n",
    "cv_scores_all = cross_validate(clf, Features, y, cv = 5, scoring=('r2'), return_train_score = True)\n",
    "print ('total variance', np.mean(cv_scores_all['train_score']), np.mean(cv_scores_all['test_score']))\n",
    "importances = []\n",
    "importances_std = []\n",
    "for i, feature in enumerate([Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C]):\n",
    "    clf = Lasso(alpha = 1e-3)\n",
    "    cv_scores = cross_validate(clf, feature, y, cv = 5, scoring=('r2'), return_train_score = True)\n",
    "    print ('total variance', np.mean(cv_scores_all['train_score'] -  cv_scores['train_score']), \\\n",
    "           np.mean(cv_scores_all['test_score'] - cv_scores['test_score']))\n",
    "    importances.append(np.mean(cv_scores_all['test_score'] - cv_scores['test_score']))\n",
    "    importances_std.append(np.std(cv_scores_all['test_score'] - cv_scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('importance_39_ran', importances)\n",
    "np.save('importance_39_ran_std', importances_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x7f96a19c2f98>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a1b6e240>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a116d2e8>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a1b27ac8>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a12f1828>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a1058240>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a12c32b0>],\n",
       " <a list of 7 Text yticklabel objects>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEBCAYAAACNPlkIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAFB9JREFUeJzt3Xm0JGV5x/HvAwhuiSgMQYmAaNSQ\nHNfRA3G7iGERcSEoS0QxKu6gAjou4LAog8qiEgUUFeOCkigIyL664IIYF1wQFPVgwAEGUZEZhCd/\nvNXMtaffe2tud1P3Xr6fc+7p7uqqus97ZqZ/U11V7xOZiSRJg6zRdQGSpNnLkJAkVRkSkqQqQ0KS\nVGVISJKqDAlJUpUhIUmqMiQkSVWGhCSpaq2uCxjWdtttl2eddVbXZUjSXBJtV5zzRxI33HBD1yVI\n0rw150NCkjQ+hoQkqcqQkCRVGRKSpCpDQpJUZUhIkqoMCUlSlSEhSaoyJCRJVYaENIdNTEwwMTHR\ndRmaxwwJSVKVISFJqjIkJElVhoQkqcqQkCRVGRKSpCpDQpJUZUhIkqoMCUlS1VpdFyDdk2y66IyR\n7u+6X9w4lv1es2SHke5Pc5dHEpKkKkNCklRlSEiSqgwJSVKVISFJqjIkJElVhoQkqcqQkCRVGRKS\npCpDQpJU5bQc0hy24e5Lui5B85xHEpKkKkNCklRlSEiSqgwJSVKVISFJqjIkJElVhoQkqcqQkCRV\nGRKSpCpDQpJUZUhIkqoMCUlSlSEhSaoyJCRJVYaEJKnKkJAkVRkSkqQqQ0KSVGVISJKqDAlJUpUh\nIUmqMiQkSVWGhCSpypCQJFUZEpKkKkNCklRlSEiSqgwJSVKVISFJqjIkJElVhoQkqcqQkCRVGRKS\npCpDQpJUZUhIkqoMCUlSlSEhSaoyJCRJVYaEJKnKkJAkVRkSkqQqQ0KSVGVISJKqDAlJUpUhIUmq\nMiQkSVWGhCSpypCQJFUZEpKkKkNCklRlSEiSqgwJSVKVISFJqjIkJElVhoQkqcqQkCRVGRKSpCpD\nQpJUZUhIkqoMCUlSlSEhSaoyJCRJVYaEJKnKkJAkVRkSkqQqQ0KSVGVISJKqDAlJUpUhIUmqMiQk\nSVWGhCSpypCQJFUZEpKkKkNCklRlSEiSqgwJSVKVISFJqjIkJElVhoQkqcqQkCRVGRKSpCpDQpJU\nZUhIkqoMCUlSlSEhSaoyJCRJVYaEJKnKkJAkVRkSkqQqQ0KSVGVISJKqDAlJUpUhIUmqMiQkSVWG\nhCSpypCQJFUZEpKkKkNCklRlSEiSqgwJSVKVISFJqmoVEhGxeUScHxG3RsRvI+LgiFhzmm3Wjoj3\nRcRXI+LPEZFTrPu8iPhhRNwWET+OiF1WdyCSpNGbNiQi4oHAeUACzwMOBvYFDppm0/sCrwBuBb4x\nxf6fCvwPcCGwPXAG8LmI2KZF/ZKkMVqrxTqvBu4D7JSZtwDnRsTfAosj4r3NslVk5s0R8aDMzIh4\nPfDMyv4PAC7JzL2b1xdGxD8BBwLnrNZoJEkj1ebrpu2Bs/vC4CRKcDxjqg0zs/oVE0BErANsBXyh\n762TgC0j4gEt6pMkjUmbkHg08NPJCzLz15SvkR495O9/OHCv/v0DP2lqe+SQ+5ckDaFNSDwQuHnA\n8mXNe8Pobd+//2V97/+ViNgrIi6LiMuWLl06ZAmSpJq2l8AO+tooKstnon8/McXvJTOPz8yFmblw\nwYIFIypBktSvTUgsA9YdsPwBDD7CWB29I4b+/fdeD7t/SdIQ2oTET+k79xARDwXux6rnElbX1cDt\n/ftvXt8JXDnk/iVJQ2gTEmcC20bE30xatgvwZ+DiYX55Zi6n3B/xwr63dgEuzczfD7N/SdJw2twn\ncSywN/DFiDgc2AxYDBw5+bLYiLgKuDgzXz5p2faUI47HNa93bt76Tmb+qnl+CHBRRBwNnAI8u/nZ\nbohxSZJGYNqQyMxlEbE1cAxwGuU8wVGUoOjfV/9UHR8BNpn0+uTm8WXAJ5v9f60Jj0OB1wC/BHbP\nTG+kk6SOtTmSIDN/TP2O6d46m7ZZVtn2FMpRhCRpFnEWWElSlSEhSaoa21ThzXYPiIhPRMSyiPh9\nRHwmItbrW2ftiDgwIq5qphS/KiIOauZ1knQPMzExwcTERNdlqDHtOYlJU4X/mDJV+MOBIygB885p\nNv888CjKlOF3AodTzj08bdI6Sygzzb4T+B7wBMpJ7HWBfdoPRZI0amObKjwitgS2BZ6RmZc0y64F\nvhURz8rM85pVdwc+kplHNq8vjIiNgH/HkJBmvU0XnTHS/V33ixvHst9rluww0v3dU4xzqvDtget7\nAQGQmd+mXOK6/aT17gX03zR3Myvnb5IkdWScU4Wvsl3jJ33bfQx4VUQ8JSLuHxFPo9wvcUyL2iRJ\nY9Tm66aZThU+1XabTXq9iHJU8rVJyz6cmQe3qE3SPLPh7ku6LkGTtLqZjplPFd5mu/2BFwNvAH4A\nPBY4JCJuzMwDB+00IvYC9gLYeOONpylBkjRTbUJiplOFLwMGNXtYt7ddRKxPuZLpdZn50eb9SyJi\nBXBMRByTmb/r30FmHg8cD7Bw4cJR9bSQJPUZ51Thq2zXmHyuYjPKiev/7Vvne5QA2wRJUmfGOVX4\nmcCGEfHU3oKIWEgJhjObRb2ZYJ/Qt+0Tm8drWtQnSRqTsU0VnpmXRsTZwKciYj9W3kz3td49Epl5\nfUScAhweEfemnJN4XLP/kzPTBtaS1KFxTxW+a7PuxylHLadTAmeylwIHNssfAlwLHEfpMyFJ6tC4\npwq/mdI74mVTbHcLsF/zI0maRZwFVpJUZUhIkqoMCUlSVef9JJr11ouI4yLiuqanxE8j4iUzGZAk\naXQ67yfRTDt+CfBHytQcNwCbA2uv3lAkSaM2G/pJvB1YB1iYmX9ull048yFJkkZlNvSTeBlwwqSA\nkCTNEp32k4iIhwEbADdHxFciYkVELI2IIyPCr5skqWNtQmIc/SR6223YPL6Xcqf1dsB7KE2HDm1R\nmyRpjLruJ9ELqSsy85XN8wuayQTfHhGLM/PWVXZgPwlJulu0OZIYpp/EoO3u6icB3NQ89p+ovoBy\nMvvhg3acmcdn5sLMXLhgwaCWFZKkUei6n8TVwIoB60TzeGeL+iRJY9JpP4nMXAGcy6qTB25NOTF+\nVYv6JElj0iYkjgWWU/pJPKs5H7CYAf0kIuKE3uvMvBTo9ZPYKSKeD3yGSf0kGgcDj2/uzN6m6T2x\nCHhPZi4fdoCSpJmbNiQycxnlf/ZrUvpJHETpEfGuvlVr/SQupvST+BTwXeAFffv/NrAj8Nhm//sA\n7wYOW72hSJJGrfN+Es16Z1OOOiRJs4izwEqSqgwJSVKVISFJqpoV/SQmrf/8iMiIuGx1BiFJGo/O\n+0lM+j33Bo4Erm9fviRpnGZDP4me/SmT/F0N/PPMhiNJGqXZ0E+CiNgYeAvlHglJ0izRaT+JSY4A\nvpCZl7eoR5J0N2nzddM4+kls1nsREVtRvpZ6ZItaets4VbikOWFiYgKAiy66qNM6ZqrTfhIRsRbw\nQeDQzLyuZS1k5vHA8QALFy6crgZJam3TRWeMdH/X/eLGsez3miU7jHR/NW1CYph+EoOaPUzuJ/HK\n5vWJEdH7HWsDazav/5SZt7eoUZI0Bm1CYph+Eqtc6trs65Tm+aOAvwcGHUUsA/YAPt2iRkmalTbc\nfUnXJQyl034SwDHAVn0/ZwNXNs/PbTcMSdI4tDmSOBbYm9JP4nDKh/xiBvSTAC7OzJdD6ScREb1+\nEvux8ma6u/pJZOZV9DUWiog9gfUz86LhhiZJGlbn/SQkSbPXrOgn0bfNnm3XlSSNl7PASpKqDAlJ\nUlWnU4VHxJoR8daI+GpE3Nj8nBMRTxpmUJKk0Zg2JCZNFZ6UqcIPBvalnMCezueBCcpU4XsCT2Ll\nPRJQJglcBHyHck/Ei4Hbga9FxBNbjkGSNCZdTxX+Z2Cz5gqq3nbnU+6TeD2rccJbkjR6nU4Vnpl3\nTA6IZtkK4Apgg1YjkCSNzWyZKvwuEbEO8ERKJzxJUofahMQ4pgqfart3NO9/rEVtkqQxansJ7Fim\nCl/ljYgdKCHx1sz8WW2nEbFXRFwWEZctXbp0mhIkSTPVJiSGmSp80HaTpwq/S3PZ6+eB4zLz6KkK\nyszjM3NhZi5csGDQbOSSpFFoExLDTBU+6NzDKucqIuKRwBnA+cAbWtQkSbobdD1VOBHxYMr04FcD\nu2XmHe3LlySNU5uQOBZYTpkq/FlNf+nFDJgqPCJO6L3OzEspH/6fioidIuL5wGeYNFV4RNyHEhgP\nBA4FHhMRWzQ/jx/NECVJMzXtzXSZuSwitqY0CDqNcj7hKEpQ9O9r0FThR1GmCl8DOJ3Sm6Ln74DH\nNs9P79v2V8Cm09UnSRqfTqcKz8xrKFc7SZJmIWeBlSRVGRKSpCpDQpJU1bafxI4RcVNEZETcEREX\nR8S9Wmz30Ij4eUTc2Wz7y4h4xID13h0RtzXrLI+IKW+mkyTdPdr0k9iU0gMiKb0fTgKeDlzQYv+X\nU65QOgI4HNgI+G7f/l8DvJ1yg92bge8D+0TEonZD0LhMTEwwMTHRdRmSOtTm6qZjKVcgPSYzrwWI\niHWBZ0fERr1l/SLilcD6wBsy85hm2U+BT0TE/pn5vmbVQ4Blmfm45vVREfE74G3AkpkO7J5o00Vn\njHaHW+w/lv1es2SHke5P0vi0CYktgN/0hcEhwLOBVwEHVrZ7MXBnLyAAMvOTEfFRyh3b72vu4l4P\n+Gzftl8C9oqIh2bmb9oNRfPRyINvTAw+zVdtzkn8LaVR0F0y85vN0ydMsd1mwB8GLF8GbNw8n2ge\nv9O3zjeaxynvzZAkjVebkAjKB3u/O5i6L8R9KfM79fsjcO/m+UbN4//1rdM7enhwi/okSWPS6o5r\n4M4By4bpJzHd/nvhVes78V/ATs3L5RHxo2nquDutD9zQdREjNPLxxOGj3NuMzLcxzbfxwPwb02wb\nz1mZuV2bFduERDL4iGENpu4ncStw/wHL7wfc1jzvnefoP2LoHWFcN7CgzD2APab43Z2JiMsyc2HX\ndYzKfBsPzL8xzbfxwPwb01weT5uvm24BHj55QUQ8uXl6+RTb/YJyPqPfA4FfN88vah6f3LfOls1j\nm8tsJUlj0iYkvgk8tOn70HNA83jcFNt9GlijuQ8CgIjYg3L08nmAzPwDcCOwfd+2LwBu8comSepW\nm5B4NeUrpx9FxP7N+YDnUPpC3HVZbESsiIi7+lJn5kcp38F9MCIOj4jDgBMoH/7vm7T/A4AHRcT3\nIuKNEfEtYAPgsKFH143juy5gxObbeGD+jWm+jQfm35jm7Hgic7pzz2VaDuBEyldFdwJfB7bOzNsn\nrfMX4JrMfMSkZZsA5wG9Zb8CtsnMK/v2fxjwJmAdYAVwbGbuM8S4JEkj0CokJEn3TM4COyJR/LKZ\npHCVSQznioj4YtOK9t4D3js7In4SEWt3UdtMRcQFEfH9iFirb/m/NX9e/9pVbasrIhY3Nf+88v5V\nzfuL7+bShhYRe0bEdyPiDxGxrPkK+siu6xpW0775goi4uZnA9MqIODQi1u+6tjYMidHZkpXtVnft\nsI5h7U1pK/u2yQsjYmdgG+A1mbmii8KG8FrgH5nUOjci7g8cDXwhM8/tqrAZug14WET81SWVEfEk\nYBNWXmI+Z0TE24CPAWdT7oF6CXAq8Nwu6xpWRBwBnEy52nMPyr+ho4AdgY92WFp7menPCH6AD1Hu\nJv8mcEXX9Qw5ln0pHzSPaF7fj3IX/Ild1zbEmA6jTBOzUfP6CMrl3Q/purbVHMdiygUh5wDv73vv\nCMqH7A3A4q5rXc1xXQv854Dl0XVtQ4xpR8pFP/8x4L01ge27rrHNj0cSIxARawIvBL4MfBzYPCIe\n021VQ/kA8DNK8AG8izLNyn6dVTS8QyiXWx/V/NnsDbwrM3/bbVkzdhLwoogIKF93Ai9qls9F6zLg\n5tlsPlHnqDcBl2fmx/vfyMw7MvPMDmpabYbEaDyT8hXNScB/A7cDu3Va0RAy8y/Aa4BtI+IA4I3A\nosxc2m1lM5eZtwL7UML8VODHrAzBueiLlL9zT21ePw1YQJlBeS66HHhDRLw0ItbruphhNU3Z/gU4\nq+tahmVIjMZulClKzsrMm4BzgV17/8ubizLzG5T7Wg6mzNL7sW4rGl5mnkpperUp8MYmDOekzLyZ\n8gHUO/+1K+Xv31RT5cxmr6N8XftJYGlEXBERB0fEoFkb5oL1KJf0/3q6FWc7Q2JIEbEO5Q7xL+XK\nE7qfo3wQbdFVXSPSu+nxiDl+2A9Ac6L38ZTviSe6rWYkTgJ2bv4O7szc/aqJzPwB5eKC5wIfpkwE\negBwWXORwVw15//dGBLD257yfepXImLdpmvfRcBy5vBXTo0VfY9zVkSsAXwEuBQ4CHhLRGzWbVVD\n+zJlEs13Uy4uOK3bcoaTmcsz87TMfH1mbg68AvgH4OUdlzYTN1I+AzaebsXZzpAYXi8ITqb03VhG\nuRJoHcqJxTW7Kkx/5dWUo4jXUtriXgt8sNOKhpSZfwJOp5wgPa15PW9k5gnATcCju65ldWWZjeLr\nwLZd1zIsQ2IIzWHwcyhfL23V9/NmyonFrTorUABExAaU/21/KDN/kJnLKVc37RARz+u2uqF9hHIE\ncWzXhQyj+TPqX7YAeABw/d1f0UgcDSyMiJf2vxERa0REq34OXWvbdEiDPY9yaegHMvNbk9+IiK8D\n76AcaZzXQW1a6f2ULonv6i3IzK9ExKnA0RFxTmYO6qI462XmRayccn8u+2Hz53EO8DvKTYH7UfrS\nnNhlYTOVmac1d4yfEBFPoVxV90fKkdGrgWuYA1c/eSQxnN2An/cHBNx1uPkFYKfmxKI6EBFPp9zp\num9m3tL39j6UGYfffrcXpn4HUy72+CAlKA4BrgCenJm/7LCuoWTmvsAulHMrn6Vc+bgvcD7lMvNZ\nzwn+JElVHklIkqoMCUlSlSEhSaoyJCRJVYaEJKnKkJAkVRkSkqQqQ0KSVGVISJKq/h9BqSmOut0o\nUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96a1b27208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = subplot(1, 1, 1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "imp = np.load('importance_39_ran.npy')\n",
    "imp_std = np.load('importance_39_ran_std.npy')\n",
    "plt.bar(np.arange(6), height = imp, yerr = imp_std)\n",
    "plt.xticks([0, 1, 2, 3, 4, 5], ['A', 'Y', 'X', 'M', 'S', 'C'], size = 15)\n",
    "plt.yticks([0, 0, 0.02, 0.04, 0.06, 0.08, 0.1], size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variance 0.31721267690645655 0.2942473889825306\n",
      "total variance 0.027002631190721216 0.026514853996747596\n",
      "total variance 0.012149880899032994 0.006382254638992124\n",
      "total variance 0.061483550335101576 0.05719279277966778\n",
      "total variance 0.04440506871493353 0.043728727474883745\n",
      "total variance 0.02152842744217217 0.021326007147972975\n",
      "total variance 0.02176225992520271 0.02195953498579638\n"
     ]
    }
   ],
   "source": [
    "# record sessions 100 for 2 different context, record the relevant variables \n",
    "weight ='weights_fix/weights1/rnn_1515tanh512_checkpoint39_2_9'\n",
    "States1, Poss1, Hiddens1, Actions1, Context1 = Data_record(weight)\n",
    "y, Features, Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C = Feature_preprocessing(States1, Poss1, Hiddens1, Actions1,\\\n",
    "                                                                                                           Context1)\n",
    "clf = Lasso(alpha = 1e-3)\n",
    "cv_scores_all = cross_validate(clf, Features, y, cv = 5, scoring=('r2'), return_train_score = True)\n",
    "print ('total variance', np.mean(cv_scores_all['train_score']), np.mean(cv_scores_all['test_score']))\n",
    "importances = []\n",
    "importances_std = []\n",
    "for i, feature in enumerate([Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C]):\n",
    "    clf = Lasso(alpha = 1e-3)\n",
    "    cv_scores = cross_validate(clf, feature, y, cv = 5, scoring=('r2'), return_train_score = True)\n",
    "    print ('total variance', np.mean(cv_scores_all['train_score'] -  cv_scores['train_score']), \\\n",
    "           np.mean(cv_scores_all['test_score'] - cv_scores['test_score']))\n",
    "    importances.append(np.mean(cv_scores_all['test_score'] - cv_scores['test_score']))\n",
    "    importances_std.append(np.std(cv_scores_all['test_score'] - cv_scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('importance_39_early', importances)\n",
    "np.save('importance_39_early_std', importances_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x7f96a21ab320>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a1740dd8>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a2080b70>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a2866470>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a13f0780>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a13f0e10>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a1fb54e0>],\n",
       " <a list of 7 Text yticklabel objects>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEDCAYAAADA9vgDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMiQkSZ3+P8zzMarTPmZwAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96a1d1c6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = subplot(1, 1, 1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "imp = np.load('importance_39_early.npy')\n",
    "imp_std = np.load('importance_39_early_std.npy')\n",
    "plt.bar(np.arange(6), height = imp, yerr = imp_std)\n",
    "plt.xticks([0, 1, 2, 3, 4, 5], ['A', 'Y', 'X', 'M', 'S', 'C'], size = 15)\n",
    "plt.yticks([0, 0, 0.02, 0.04, 0.06, 0.08, 0.1], size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variance 0.3293548604588767 0.302178242437437\n",
      "total variance 0.023281584548012914 0.02268872299490212\n",
      "total variance 0.010922114970701613 0.006340058649743708\n",
      "total variance 0.06191556487930637 0.058104443962850395\n",
      "total variance 0.05568991566761493 0.05317901535938727\n",
      "total variance 0.021861688208954243 0.02155693360398636\n",
      "total variance 0.028074375152168464 0.027763299692792842\n"
     ]
    }
   ],
   "source": [
    "# record sessions 100 for 2 different context, record the relevant variables \n",
    "weight ='weights_fix/weights1/rnn_1515tanh512_checkpoint39_2_9'\n",
    "States1, Poss1, Hiddens1, Actions1, Context1 = Data_record(weight)\n",
    "y, Features, Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C = Feature_preprocessing(States1, Poss1, Hiddens1, Actions1,\\\n",
    "                                                                                                           Context1)\n",
    "clf = Lasso(alpha = 1e-3)\n",
    "cv_scores_all = cross_validate(clf, Features, y, cv = 5, scoring=('r2'), return_train_score = True)\n",
    "print ('total variance', np.mean(cv_scores_all['train_score']), np.mean(cv_scores_all['test_score']))\n",
    "importances = []\n",
    "importances_std = []\n",
    "for i, feature in enumerate([Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C]):\n",
    "    clf = Lasso(alpha = 1e-3)\n",
    "    cv_scores = cross_validate(clf, feature, y, cv = 5, scoring=('r2'), return_train_score = True)\n",
    "    print ('total variance', np.mean(cv_scores_all['train_score'] -  cv_scores['train_score']), \\\n",
    "           np.mean(cv_scores_all['test_score'] - cv_scores['test_score']))\n",
    "    importances.append(np.mean(cv_scores_all['test_score'] - cv_scores['test_score']))\n",
    "    importances_std.append(np.std(cv_scores_all['test_score'] - cv_scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('importance_39', importances)\n",
    "np.save('importance_39_std', importances_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x7f96a0da35c0>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a0da3d68>],\n",
       " <a list of 2 Text yticklabel objects>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEDCAYAAADdpATdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nX5IKMv6SVND/A321r3/P3zgKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96a0dfbb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = subplot(1, 1, 1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "imp = np.load('importance_39.npy')\n",
    "imp_std = np.load('importance_39_std.npy')\n",
    "plt.bar(np.arange(6), height = imp, yerr = imp_std)\n",
    "plt.xticks([0, 1, 2, 3, 4, 5], ['A', 'Y', 'X', 'M', 'S', 'C'], size = 15)\n",
    "plt.yticks([0, 0.1], size = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(np.array(entropy1))\n",
    "plt.figure()\n",
    "plt.hist(np.array(entropy2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain Net2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variance 0.48801937512183163 0.47862559380930403\n",
      "total variance 0.0054364210886023836 0.0049760003762125745\n",
      "total variance 0.017238618699956965 0.015518189510648095\n",
      "total variance 0.013729599098896428 0.012327570184542547\n",
      "total variance 0.2047673708895889 0.21098770605324338\n",
      "total variance 0.07701052149262691 0.07779149437159348\n",
      "total variance 0.028704327767368153 0.02912998770702563\n"
     ]
    }
   ],
   "source": [
    "weight = 'weights_fix_pre2/weights1/rnn_1515tanh512_checkpoint49_0_9'\n",
    "# loadweight(weight_load = 'weights_cpu8/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "States1, Poss1, Hiddens1, Actions1, Context1 = Data_record(weight)\n",
    "y, Features, Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C = Feature_preprocessing(States1, Poss1, Hiddens1, Actions1,\\\n",
    "                                                                                                           Context1)\n",
    "clf = Lasso(alpha = 1e-3)\n",
    "cv_scores_all = cross_validate(clf, Features, y, cv = 5, scoring=('r2'), return_train_score = True)\n",
    "print ('total variance', np.mean(cv_scores_all['train_score']), np.mean(cv_scores_all['test_score']))\n",
    "importances = []\n",
    "importances_std = []\n",
    "for i, feature in enumerate([Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C]):\n",
    "    clf = Lasso(alpha = 1e-3)\n",
    "    cv_scores = cross_validate(clf, feature, y, cv = 5, scoring=('r2'), return_train_score = True)\n",
    "    print ('total variance', np.mean(cv_scores_all['train_score'] -  cv_scores['train_score']), \\\n",
    "           np.mean(cv_scores_all['test_score'] - cv_scores['test_score']))\n",
    "    importances.append(np.mean(cv_scores_all['test_score'] - cv_scores['test_score']))\n",
    "    importances_std.append(np.std(cv_scores_all['test_score'] - cv_scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('importance_49', importances)\n",
    "np.save('importance_49_std', importances_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x7f96a0f92710>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a0e43b70>],\n",
       " <a list of 2 Text yticklabel objects>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEBCAYAAACQbKXWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npIKMvyQVZPwlqSDjL0kFGX9JKuj/AMt7r+67APb3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96a0dfb748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = subplot(1, 1, 1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "imp = np.load('importance_49.npy')\n",
    "imp_std = np.load('importance_49_std.npy')\n",
    "plt.bar(np.arange(6), height = imp, yerr = imp_std)\n",
    "plt.xticks([0, 1, 2, 3, 4, 5], ['A', 'Y', 'X', 'M', 'S', 'C'], size = 15)\n",
    "plt.yticks([0, 0.1], size = 15)\n",
    "# plt.ylim(0, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a SVM decoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06737138830162086\n"
     ]
    }
   ],
   "source": [
    "# increasing action 10 times will increase decoding efficientcy by 10 %\n",
    "weight ='weights_fix/weights1/rnn_1515tanh512_checkpoint0_0_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, k_action = 1, T = 800, seed_num = 1e6, epsilon = 1)\n",
    "States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context)\n",
    "X = np.array(Hiddens[Status>0])\n",
    "Y = [p[1] + p[0] * 15 for p in Poss[Status>0]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "gammas = [1e-2]\n",
    "for gamma in gammas:\n",
    "    model = sklearn.svm.SVC(C = 1e5, gamma = gamma, kernel = 'linear')\n",
    "    model.fit(X_train, y_train)\n",
    "    print (f1_score(y_test, model.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2199999999999998"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(np.array(y_test[:100])//15 - model.predict(X_test[:100])//15).mean() + np.abs(np.array(y_test[:100])%15 -  model.predict(X_test[:100])%15).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05145665145665146\n"
     ]
    }
   ],
   "source": [
    "# increasing action 10 times will increase decoding efficientcy by 10 %\n",
    "weight ='weights_fix/weights1/rnn_1515tanh512_checkpoint0_0_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, k_action = 1, T = 800, seed_num = 1e6, epsilon = 1)\n",
    "States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context)\n",
    "X = np.array(Hiddens[Status>0][:-2])\n",
    "Y = [p[1] + p[0] * 15 for p in Poss[Status>0][2:]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "gammas = [1e-2]\n",
    "for gamma in gammas:\n",
    "    model1 = sklearn.svm.SVC(C = 1e5, gamma = gamma, kernel = 'linear')\n",
    "    model1.fit(X_train, y_train)\n",
    "    print (f1_score(y_test, model1.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.56"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(np.array(y_test[:100])//15 - model1.predict(X_test[:100])//15).mean() + np.abs(np.array(y_test[:100])%15 -  model1.predict(X_test[:100])%15).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.039778307843412374\n"
     ]
    }
   ],
   "source": [
    "# increasing action 10 times will increase decoding efficientcy by 10 %\n",
    "weight ='weights_fix/weights1/rnn_1515tanh512_checkpoint39_0_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, k_action = 1, T = 800, seed_num = 1e6, epsilon = 1)\n",
    "States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context)\n",
    "X = np.array(Hiddens[Status>0][:-2])\n",
    "Y = [p[1] + p[0] * 15 for p in Poss[Status>0][2:]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "gammas = [1e-2]\n",
    "for gamma in gammas:\n",
    "    model1 = sklearn.svm.SVC(C = 1e5, gamma = gamma, kernel = 'linear')\n",
    "    model1.fit(X_train, y_train)\n",
    "    print (f1_score(y_test, model1.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(np.array(y_test[:100])//15 - model1.predict(X_test[:100])//15).mean() + np.abs(np.array(y_test[:100])%15 -  model1.predict(X_test[:100])%15).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0569691829233814\n"
     ]
    }
   ],
   "source": [
    "# increasing action 10 times will increase decoding efficientcy by 10 %\n",
    "weight ='weights_fix/weights1/rnn_1515tanh512_checkpoint39_0_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, k_action = 1, T = 800, seed_num = 1e6, epsilon = 1)\n",
    "States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context)\n",
    "X = np.array(Hiddens[Status>0])\n",
    "Y = [p[1] + p[0] * 15 for p in Poss[Status>0]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "gammas = [1e-2]\n",
    "for gamma in gammas:\n",
    "    model1 = sklearn.svm.SVC(C = 1e5, gamma = gamma, kernel = 'linear')\n",
    "    model1.fit(X_train, y_train)\n",
    "    print (f1_score(y_test, model1.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.45"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(np.array(y_test[:100])//15 - model1.predict(X_test[:100])//15).mean() + np.abs(np.array(y_test[:100])%15 -  model1.predict(X_test[:100])%15).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06090251464002756\n"
     ]
    }
   ],
   "source": [
    "weight ='weights_fix_pre2/weights1/rnn_1515tanh512_checkpoint49_1_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, k_action = 1, epsilon = 1, T = 800, seed_num = 1e6)\n",
    "States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context)\n",
    "X = np.array(Hiddens[Status>0])\n",
    "Y = [p[1] + p[0] * 15 for p in Poss[Status>0]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "gammas = [1e-2]\n",
    "for gamma in gammas:\n",
    "    model1 = sklearn.svm.SVC(C = 1e5, gamma = gamma, kernel = 'linear')\n",
    "    model1.fit(X_train, y_train)\n",
    "    print (f1_score(y_test, model1.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.43"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(np.array(y_test[:100])//15 - model1.predict(X_test[:100])//15).mean() + np.abs(np.array(y_test[:100])%15 -  model1.predict(X_test[:100])%15).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6783576308190717\n"
     ]
    }
   ],
   "source": [
    "weight ='weights_fix/weights1/rnn_1515tanh512_checkpoint0_0_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, k_action = 1, epsilon = 1, T = 800, seed_num = 1e6, size = 30)\n",
    "States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context, size = 15)\n",
    "X = np.array(Hiddens[Status>0])\n",
    "Y = Status[Status>0]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "model = sklearn.linear_model.LogisticRegression(C = 1e5)\n",
    "model.fit(X_train, y_train)\n",
    "print (f1_score(y_test, model.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.630360236150882\n"
     ]
    }
   ],
   "source": [
    "weight ='weights_fix/weights1/rnn_1515tanh512_checkpoint39_0_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, k_action = 1, epsilon = 1, T = 800, seed_num = 1e6, size = 30)\n",
    "States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context, size = 15)\n",
    "X = np.array(Hiddens[Status>0])\n",
    "Y = Status[Status>0]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "model = sklearn.linear_model.LogisticRegression(C = 1e5)\n",
    "model.fit(X_train, y_train)\n",
    "print (f1_score(y_test, model.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7225123833271556\n"
     ]
    }
   ],
   "source": [
    "weight ='weights_fix_pre2/weights1/rnn_1515tanh512_checkpoint49_1_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, k_action = 1, epsilon = 1, T = 800, seed_num = 1e6, size = 30)\n",
    "States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context, size = 15)\n",
    "X = np.array(Hiddens[Status>0])\n",
    "Y = Status[Status>0]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "model = sklearn.linear_model.LogisticRegression(C = 1e5)\n",
    "model.fit(X_train, y_train)\n",
    "print (f1_score(y_test, model.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8517792098627066\n"
     ]
    }
   ],
   "source": [
    "weight ='weights_fix/weights1/rnn_1515tanh512_checkpoint0_0_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, epsilon = 1, k_action = 1, T = 400, seed_num = 1e6)\n",
    "States, Poss, Hiddens, Actions, Status, Context, Memory = Transform(States, Poss, Hiddens, Actions, Context, history = True)\n",
    "\n",
    "Mem = np.array([mem[1] + 4 * mem[0] for mem in Memory])\n",
    "\n",
    "X = np.array(Hiddens[Status>0])\n",
    "Y = Mem[Status>0]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "gammas = [1e-2]\n",
    "for gamma in gammas:\n",
    "    model1 = sklearn.svm.SVC(C = 1e5, gamma = gamma, kernel = 'linear')\n",
    "    model1.fit(X_train, y_train)\n",
    "    print (f1_score(y_test, model1.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6976256983240223\n"
     ]
    }
   ],
   "source": [
    "weight ='weights_fix/weights1/rnn_1515tanh512_checkpoint39_0_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, epsilon = 1, k_action = 1, T = 400, seed_num = 1e6)\n",
    "States, Poss, Hiddens, Actions, Status, Context, Memory = Transform(States, Poss, Hiddens, Actions, Context, history = True)\n",
    "\n",
    "Mem = np.array([mem[1] + 4 * mem[0] for mem in Memory])\n",
    "\n",
    "X = np.array(Hiddens[Status>0])\n",
    "Y = Mem[Status>0]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "gammas = [1e-2]\n",
    "for gamma in gammas:\n",
    "    model1 = sklearn.svm.SVC(C = 1e5, gamma = gamma, kernel = 'linear')\n",
    "    model1.fit(X_train, y_train)\n",
    "    print (f1_score(y_test, model1.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7255192878338279\n"
     ]
    }
   ],
   "source": [
    "weight ='weights_fix_pre2/weights1/rnn_1515tanh512_checkpoint49_1_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, epsilon = 1, k_action = 1, T = 400, seed_num = 1e6)\n",
    "States, Poss, Hiddens, Actions, Status, Context, Memory = Transform(States, Poss, Hiddens, Actions, Context, history = True)\n",
    "\n",
    "Mem = np.array([mem[1] + 4 * mem[0] for mem in Memory])\n",
    "\n",
    "X = np.array(Hiddens[Status>0])\n",
    "Y = Mem[Status>0]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "gammas = [1e-2]\n",
    "for gamma in gammas:\n",
    "    model1 = sklearn.svm.SVC(C = 1e5, gamma = gamma, kernel = 'linear')\n",
    "    model1.fit(X_train, y_train)\n",
    "    print (f1_score(y_test, model1.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "**The strongest property of pretrain net, no matter it is in the obstacle case or no hole case, is the strong presence of position/x signal in the code **"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "759px",
    "left": "0px",
    "right": "1228px",
    "top": "67px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
