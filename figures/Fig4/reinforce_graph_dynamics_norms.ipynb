{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#quick-start\" data-toc-modified-id=\"quick-start-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>quick start</a></span><ul class=\"toc-item\"><li><span><a href=\"#Resources\" data-toc-modified-id=\"Resources-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Resources</a></span></li></ul></li><li><span><a href=\"#FULL-MODEL\" data-toc-modified-id=\"FULL-MODEL-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>FULL MODEL</a></span><ul class=\"toc-item\"><li><span><a href=\"#Packages\" data-toc-modified-id=\"Packages-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Packages</a></span><ul class=\"toc-item\"><li><span><a href=\"#Qnetwork\" data-toc-modified-id=\"Qnetwork-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Qnetwork</a></span></li></ul></li><li><span><a href=\"#POMDP-RNN-Game\" data-toc-modified-id=\"POMDP-RNN-Game-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>POMDP RNN Game</a></span></li><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Results</a></span><ul class=\"toc-item\"><li><span><a href=\"#Standard-setting：-grid-=--(3,7)，-holes-=-0\" data-toc-modified-id=\"Standard-setting：-grid-=--(3,7)，-holes-=-0-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Standard setting： grid =  (3,7)， holes = 0</a></span></li><li><span><a href=\"#Model-Tranining\" data-toc-modified-id=\"Model-Tranining-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Model Tranining</a></span></li><li><span><a href=\"#decoding-vs-performance\" data-toc-modified-id=\"decoding-vs-performance-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>decoding vs performance</a></span></li><li><span><a href=\"#learning-rate-vs-performance\" data-toc-modified-id=\"learning-rate-vs-performance-2.3.4\"><span class=\"toc-item-num\">2.3.4&nbsp;&nbsp;</span>learning rate vs performance</a></span></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-2.3.5\"><span class=\"toc-item-num\">2.3.5&nbsp;&nbsp;</span>Summary</a></span></li><li><span><a href=\"#Anlytic-part-,-check-the-behaviour-correspond-to-each-decoding-level-and-explain-why\" data-toc-modified-id=\"Anlytic-part-,-check-the-behaviour-correspond-to-each-decoding-level-and-explain-why-2.3.6\"><span class=\"toc-item-num\">2.3.6&nbsp;&nbsp;</span>Anlytic part , check the behaviour correspond to each decoding level and explain why</a></span></li></ul></li><li><span><a href=\"#PCA\" data-toc-modified-id=\"PCA-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>PCA</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quick start "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This study tries to loop upon each strategy on its own decoding/navigation performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Somethings to study**:\n",
    "1.  Take the overall statistics of results, compare what is qualitative change between echo state and pretrained network of different eigen values. Slightly better generalization of pretrained net in overall \n",
    "2.  Relation of decoding vs performance  Does decoding predicts small size performance?  Does decoding generalization performance? Does the decoding evolving in the q leanring predicts anything?   \n",
    "3.  Does the eigen values, which are the fingerprint of dynamics, predicts anything?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "* [*The* Reinforcement learning book from Sutton & Barto](http://incompleteideas.net/sutton/book/the-book-2nd.html)\n",
    "* [The REINFORCE paper from Ronald J. Williams (1992)](http://www-anw.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tie/anaconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import init\n",
    "from torch.nn import DataParallel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML\n",
    "\n",
    "import pretrain\n",
    "from pretrain import *\n",
    "\n",
    "import navigation2\n",
    "from navigation2 import *\n",
    "\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "from scipy import signal\n",
    "\n",
    "import Nets\n",
    "from Nets import*\n",
    "\n",
    "%pylab inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Norm summary for different networks \n",
    "Try to get all performances 15, 35, 55, 85 here.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to understand the relation between principle component and the eigen vector = attractor here.   principle component should reflect this attractor state？  \n",
    "nets1 = np.arange(40)\n",
    "Nhh = []\n",
    "Nah = []\n",
    "Nih = []\n",
    "Nets = [nets1]\n",
    "for net in range(1):\n",
    "    nhhs= []\n",
    "    nahs = []\n",
    "    nihs = []\n",
    "    index = Nets[net]\n",
    "    for trial in index:\n",
    "#       readout weight as trained\n",
    "        Net = torch.load('weights_pre2/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        nhh = torch.norm(Net['h2h']).cpu().data.numpy().copy()\n",
    "        nah =  torch.norm(Net['a2h']).cpu().data.numpy().copy()\n",
    "        nih =  torch.norm(Net['i2h']).cpu().data.numpy().copy(0)\n",
    "        nhhs.append(nhh)\n",
    "        nahs.append(nah)\n",
    "        nihs.append(nih)\n",
    "    Nhh.append(np.array(nhhs))\n",
    "    Nah.append(np.array(nahs))\n",
    "    Nih.append(np.array(nihs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Nhh_pre2', Nhh)\n",
    "np.save('Nah_pre2', Nah)\n",
    "np.save('Nih_pre2', Nih)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to understand the relation between principle component and the eigen vector = attractor here.   principle component should reflect this attractor state？  \n",
    "nets1 = np.arange(40)\n",
    "Nhh = []\n",
    "Nah = []\n",
    "Nih = []\n",
    "Nets = [nets1]\n",
    "for net in range(1):\n",
    "    nhhs= []\n",
    "    nahs = []\n",
    "    nihs = []\n",
    "    index = Nets[net]\n",
    "    for trial in index:\n",
    "#       readout weight as trained\n",
    "        Net = torch.load('weights_pre2_wah/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        nhh = torch.norm(Net['h2h']).cpu().data.numpy().copy()\n",
    "        nah =  torch.norm(Net['a2h']).cpu().data.numpy().copy()\n",
    "        nih =  torch.norm(Net['i2h']).cpu().data.numpy().copy(0)\n",
    "        nhhs.append(nhh)\n",
    "        nahs.append(nah)\n",
    "        nihs.append(nih)\n",
    "    Nhh.append(np.array(nhhs))\n",
    "    Nah.append(np.array(nahs))\n",
    "    Nih.append(np.array(nihs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Nhh_pre2_wah', Nhh)\n",
    "np.save('Nah_pre2_wah', Nah)\n",
    "np.save('Nih_pre2_wah', Nih)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to understand the relation between principle component and the eigen vector = attractor here.   principle component should reflect this attractor state？  \n",
    "nets1 = np.arange(40)\n",
    "Nhh = []\n",
    "Nah = []\n",
    "Nih = []\n",
    "Nets = [nets1]\n",
    "for net in range(1):\n",
    "    nhhs= []\n",
    "    nahs = []\n",
    "    nihs = []\n",
    "    index = Nets[net]\n",
    "    for trial in index:\n",
    "#       readout weight as trained\n",
    "        Net = torch.load('weights_cpu1/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        nhh = torch.norm(Net['h2h']).cpu().data.numpy().copy()\n",
    "        nah =  torch.norm(Net['a2h']).cpu().data.numpy().copy()\n",
    "        nih =  torch.norm(Net['i2h']).cpu().data.numpy().copy(0)\n",
    "        nhhs.append(nhh)\n",
    "        nahs.append(nah)\n",
    "        nihs.append(nih)\n",
    "    Nhh.append(np.array(nhhs))\n",
    "    Nah.append(np.array(nahs))\n",
    "    Nih.append(np.array(nihs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Nhh_pre1', Nhh)\n",
    "np.save('Nah_pre1', Nah)\n",
    "np.save('Nih_pre1', Nih)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to understand the relation between principle component and the eigen vector = attractor here.   principle component should reflect this attractor state？  \n",
    "nets1 = np.arange(40)\n",
    "Nhh = []\n",
    "Nah = []\n",
    "Nih = []\n",
    "Nets = [nets1]\n",
    "for net in range(1):\n",
    "    nhhs= []\n",
    "    nahs = []\n",
    "    nihs = []\n",
    "    index = Nets[net]\n",
    "    for trial in index:\n",
    "#       readout weight as trained\n",
    "        Net = torch.load('weights_cpu2/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        nhh = torch.norm(Net['h2h']).cpu().data.numpy().copy()\n",
    "        nah =  torch.norm(Net['a2h']).cpu().data.numpy().copy()\n",
    "        nih =  torch.norm(Net['i2h']).cpu().data.numpy().copy(0)\n",
    "        nhhs.append(nhh)\n",
    "        nahs.append(nah)\n",
    "        nihs.append(nih)\n",
    "    Nhh.append(np.array(nhhs))\n",
    "    Nah.append(np.array(nahs))\n",
    "    Nih.append(np.array(nihs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Nhh_pre1_2', Nhh)\n",
    "np.save('Nah_pre1_2', Nah)\n",
    "np.save('Nih_pre1_2', Nih)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to understand the relation between principle component and the eigen vector = attractor here.   principle component should reflect this attractor state？  \n",
    "nets1 = np.arange(20)\n",
    "Nhh = []\n",
    "Nah = []\n",
    "Nih = []\n",
    "Nets = [nets1]\n",
    "for net in range(1):\n",
    "    nhhs= []\n",
    "    nahs = []\n",
    "    nihs = []\n",
    "    index = Nets[net]\n",
    "    for trial in index:\n",
    "#       readout weight as trained\n",
    "        Net = torch.load('weights_cpu_stim_xy/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        nhh = torch.norm(Net['h2h']).cpu().data.numpy().copy()\n",
    "        nah =  torch.norm(Net['a2h']).cpu().data.numpy().copy()\n",
    "        nih =  torch.norm(Net['i2h']).cpu().data.numpy().copy(0)\n",
    "        nhhs.append(nhh)\n",
    "        nahs.append(nah)\n",
    "        nihs.append(nih)\n",
    "    Nhh.append(np.array(nhhs))\n",
    "    Nah.append(np.array(nahs))\n",
    "    Nih.append(np.array(nihs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Nhh_pre_mix', Nhh)\n",
    "np.save('Nah_pre_mix', Nah)\n",
    "np.save('Nih_pre_mix', Nih)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to understand the relation between principle component and the eigen vector = attractor here.   principle component should reflect this attractor state？  \n",
    "nets1 = np.arange(35)\n",
    "Nhh = []\n",
    "Nah = []\n",
    "Nih = []\n",
    "Nets = [nets1]\n",
    "for net in range(1):\n",
    "    nhhs= []\n",
    "    nahs = []\n",
    "    nihs = []\n",
    "    index = Nets[net]\n",
    "    for trial in index:\n",
    "#       readout weight as trained\n",
    "        Net = torch.load('weights_cpu_xy_noinfo/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        nhh = torch.norm(Net['h2h']).cpu().data.numpy().copy()\n",
    "        nah =  torch.norm(Net['a2h']).cpu().data.numpy().copy()\n",
    "        nih =  torch.norm(Net['i2h']).cpu().data.numpy().copy(0)\n",
    "        nhhs.append(nhh)\n",
    "        nahs.append(nah)\n",
    "        nihs.append(nih)\n",
    "    Nhh.append(np.array(nhhs))\n",
    "    Nah.append(np.array(nahs))\n",
    "    Nih.append(np.array(nihs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Nhh_xy_noinfo', Nhh)\n",
    "np.save('Nah_xy_noinfo', Nah)\n",
    "np.save('Nih_xy_noinfo', Nih)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to understand the relation between principle component and the eigen vector = attractor here.   principle component should reflect this attractor state？  \n",
    "nets1 = np.arange(400)\n",
    "Nhh = []\n",
    "Nah = []\n",
    "Nih = []\n",
    "Nets = [nets1]\n",
    "for net in range(1):\n",
    "    nhhs= []\n",
    "    nahs = []\n",
    "    nihs = []\n",
    "    index = Nets[net]\n",
    "    for trial in index:\n",
    "#       readout weight as trained\n",
    "        Net = torch.load('weights_cpu_pos/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "        nhh = torch.norm(Net['h2h']).cpu().data.numpy().copy()\n",
    "        nah =  torch.norm(Net['a2h']).cpu().data.numpy().copy()\n",
    "        nih =  torch.norm(Net['i2h']).cpu().data.numpy().copy(0)\n",
    "        nhhs.append(nhh)\n",
    "        nahs.append(nah)\n",
    "        nihs.append(nih)\n",
    "    Nhh.append(np.array(nhhs))\n",
    "    Nah.append(np.array(nahs))\n",
    "    Nih.append(np.array(nihs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Nhh_pos', Nhh)\n",
    "np.save('Nah_pos', Nah)\n",
    "np.save('Nih_pos', Nih)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# taket the egien values corresponding to selected neurons\n",
    "ax = subplot(1, 1, 1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "\n",
    "Eigen_img_pre1 = np.load('Eigen_img.npy')\n",
    "Eigen_real_min_pre1  =  np.load('Eigen_real_min.npy')\n",
    "Eigen_img_pre2 = np.array(Eigen_img)\n",
    "Eigen_real_max_pre2 = np.array(Eigen_real_max)\n",
    "Eigen_real_min_pre2 = np.array(Eigen_real_min)\n",
    "plt.plot(Eigen_img_pre2[0].ravel(), Eigen_real_min_pre2[0].ravel(), 'r.')\n",
    "plt.plot(Eigen_img_pre1[0].ravel(), Eigen_real_min_pre1[0].ravel(), 'g.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff4a95dedd8>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEBCAYAAACOpZVlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFxGJMAVxEZEIUxAXEYkwBXERkQj7f8oZMi5aeiU5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff4ad0f8e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pretrain2\n",
    "Nhh = np.load('Nhh_pre2.npy')\n",
    "Nah = np.load('Nah_pre2.npy')\n",
    "Nih = np.load('Nih_pre2.npy')\n",
    "ax = subplot(1, 1, 1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "# plt.figure(0)\n",
    "plt.plot(np.array(Nhh).ravel()/Nhh[0, 0], np.array(Nah).ravel()/Nah[0, 0], 'g.')\n",
    "# pretrain1\n",
    "plt.plot(np.array(Nhh).ravel()/Nhh[0, 0], np.array(Nih).ravel()/Nih[0, 0], 'g.')\n",
    "Nhh = np.load('Nhh_pre1.npy')\n",
    "Nah = np.load('Nah_pre1.npy')\n",
    "Nih = np.load('Nih_pre1.npy')\n",
    "ax = subplot(1, 1, 1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.yaxis.set_ticks_position('left')\n",
    "ax.xaxis.set_ticks_position('bottom')\n",
    "# plt.figure(0)\n",
    "plt.plot(np.array(Nhh).ravel()/Nhh[0, 0], np.array(Nah).ravel()/Nah[0, 0], 'm.')\n",
    "plt.xticks([0.8, 1, 1.2], size = 15)\n",
    "plt.yticks([1, 3, 5], size = 15)\n",
    "\n",
    "Nhh = np.load('Nhh_pos.npy')\n",
    "Nah = np.load('Nah_pos.npy')\n",
    "Nih = np.load('Nih_pos.npy')\n",
    "plt.plot(np.array(Nhh).ravel()/Nhh[0, 0], np.array(Nah).ravel()/Nah[0, 0], 'r.', alpha = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance_s_early_abs = np.load('performance_s_early_abs.npy')\n",
    "# Performance_l_early_3 = np.load('performance_l_early_net_3.npy')\n",
    "Performance_echo_abs = np.load('Performance_echo_position.npy')[0]\n",
    "Performance_echo_abs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Performance_exxl = np.concatenate((Performance_exxl_late_1[0], Performance_exxl_late_2[0], Performance_exxl_late_3[0]), axis = 0)\n",
    "Performance_exl = np.concatenate((Performance_exl_late_1[0], Performance_exl_late_2[0], Performance_exl_late_3[0]), axis = 0)\n",
    "Performance_l = np.concatenate((Performance_l_late_1[0], Performance_l_late_2[0], Performance_l_late_3[0]), axis = 0)\n",
    "Performance_m = np.concatenate((Performance_m_late_1[0], Performance_m_late_2[0], Performance_m_late_3[0]), axis = 0)\n",
    "Performance_s = np.concatenate((Performance_s_late_1[0], Performance_s_late_2[0], Performance_s_late_3[0]), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Net\n",
    "draw pictures about the echo state and largest training samples performance evolution & generalization   Add path integrator or position network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "longer time, there is no pheonmean associate with multi-stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here with action feedback, dynamics shift to a totally different regime which is around hopf bifurcation, but it is not hugely shaped by the stimulus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this graph of PC, we will see that the representation states of trajectory (3,5) and (14,5) are actually qutie close to each other , reflecting symmetry in real space, it is in spirit of predictive decoding, using least number of interal states to play well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "**Internal dynamics rather than decoding performance influences more the performance in uncertain enviroments**\n",
    "\n",
    "**Consider to think in global loops rather than separated system, thus the coupled dynamical system.  This system, which has its genome on its internal weights, will have quite different different pheno-types from the global loops,  richness of internal dynamics turns into extenable phenotypes which supports behaviours across scales.   The different types of attractors, fix point, limit cycle becomes substrate of strategy in different size rooms.  Thus generalization can be done until certain size, which offers complicate behaviour with a \"simple mind\"**\n",
    "\n",
    "**The triangle between decoding, dynamics and navigation should be like: 1, dynamics coded by internal weight is most fundamental, it gives rise to different representations(phenotypes).   2,  The relation between decoding and navigation are reciprocal. not random behaviour gives better enviromental prediction(complement the free energy principle) 2,  we should distinguish internal dynamics and global dynamics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "759px",
    "left": "0px",
    "right": "1228px",
    "top": "67px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
