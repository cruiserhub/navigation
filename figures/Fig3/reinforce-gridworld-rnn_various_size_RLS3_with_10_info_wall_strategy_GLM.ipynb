{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#quick-start\" data-toc-modified-id=\"quick-start-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>quick start</a></span><ul class=\"toc-item\"><li><span><a href=\"#Resources\" data-toc-modified-id=\"Resources-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Resources</a></span></li></ul></li><li><span><a href=\"#FULL-MODEL\" data-toc-modified-id=\"FULL-MODEL-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>FULL MODEL</a></span><ul class=\"toc-item\"><li><span><a href=\"#Packages\" data-toc-modified-id=\"Packages-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Packages</a></span><ul class=\"toc-item\"><li><span><a href=\"#Qnetwork\" data-toc-modified-id=\"Qnetwork-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Qnetwork</a></span></li></ul></li><li><span><a href=\"#POMDP-RNN-Game\" data-toc-modified-id=\"POMDP-RNN-Game-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>POMDP RNN Game</a></span></li><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Results</a></span><ul class=\"toc-item\"><li><span><a href=\"#Standard-setting：-grid-=--(3,7)，-holes-=-0\" data-toc-modified-id=\"Standard-setting：-grid-=--(3,7)，-holes-=-0-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Standard setting： grid =  (3,7)， holes = 0</a></span></li><li><span><a href=\"#Model-Tranining\" data-toc-modified-id=\"Model-Tranining-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Model Tranining</a></span></li><li><span><a href=\"#decoding-vs-performance\" data-toc-modified-id=\"decoding-vs-performance-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>decoding vs performance</a></span></li><li><span><a href=\"#learning-rate-vs-performance\" data-toc-modified-id=\"learning-rate-vs-performance-2.3.4\"><span class=\"toc-item-num\">2.3.4&nbsp;&nbsp;</span>learning rate vs performance</a></span></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-2.3.5\"><span class=\"toc-item-num\">2.3.5&nbsp;&nbsp;</span>Summary</a></span></li><li><span><a href=\"#Anlytic-part-,-check-the-behaviour-correspond-to-each-decoding-level-and-explain-why\" data-toc-modified-id=\"Anlytic-part-,-check-the-behaviour-correspond-to-each-decoding-level-and-explain-why-2.3.6\"><span class=\"toc-item-num\">2.3.6&nbsp;&nbsp;</span>Anlytic part , check the behaviour correspond to each decoding level and explain why</a></span></li></ul></li><li><span><a href=\"#PCA\" data-toc-modified-id=\"PCA-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>PCA</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quick start "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check relation betweeen dynamics and generalization.   Hypothesis to make: generalization can only be understood in level of joint dynamical system, there is a clear link between the two**\n",
    "\n",
    "**Dynamnics determines generalization , not decoding , same decoding level can have very different dynamics , thus different generalization level.  Only when the dynamics of RNN forms object correspond to real relevant objects for game, the generalization can be good.   For instance , in a varying size game, you extend the size of game from 10 to 30, what will happen?  You can do a kind of dynamical programing , according to which wall you have seen and how many steps you have passed , you decide future action.    This can be achieved robustly by the dynamical system where fix points are correspond to walls**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "* [*The* Reinforcement learning book from Sutton & Barto](http://incompleteideas.net/sutton/book/the-book-2nd.html)\n",
    "* [The REINFORCE paper from Ronald J. Williams (1992)](http://www-anw.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tie/anaconda3/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['random']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import init\n",
    "from torch.nn import DataParallel\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML\n",
    "\n",
    "import pretrain\n",
    "from pretrain import *\n",
    "\n",
    "import navigation2\n",
    "from navigation2 import *\n",
    "\n",
    "import Nets \n",
    "from Nets import *\n",
    "\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.manifold import SpectralEmbedding\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import scipy\n",
    "from scipy.spatial import distance\n",
    "from scipy import signal\n",
    "\n",
    "import dynamics \n",
    "from dynamics import * \n",
    "\n",
    "\n",
    "%pylab inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the liquid state approach to work, you need a lot of neurons as surplus or enough hidden to hidden connectivity to make it have an effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is the relation to head direction, this order kept in limit cycle**\n",
    "**Could we define the order parameter for behaviour and link it to dynamics?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The GLM analysis of variance for different variables\n",
    "The features include x, y, sensory,  action, last click memory , last twice click memory, the last twice click has a very strong contribution to features, but it inludes the last one click. In a sense, the integrated memory is not equalling to memroy 1 plus memory2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the stimulus memory(status) and action base for memory and navigation  \n",
    "def Transform(States, Poss, Hiddens, Actions, Context, Values, history = False, size = 15):\n",
    "    # last click state\n",
    "    Borders = np.concatenate([State_transform(state, poss, size)[0] for state, poss in zip(States, Poss)])\n",
    "    Status = np.concatenate([State_transform(state, poss, size)[1] for state, poss in zip(States, Poss)])\n",
    "    Hiddens = np.concatenate(Hiddens)\n",
    "    Poss = np.concatenate(Poss)\n",
    "    Actions = np.concatenate(Actions)\n",
    "    Context = np.concatenate(Context)\n",
    "    # transform state to stim　\n",
    "    States = np.concatenate(States)\n",
    "    Values = np.concatenate(Values)\n",
    "    # transform status to memory\n",
    "    return Borders[Status>0], Poss[Status>0], Hiddens[Status>0], \\\n",
    "Actions[Status>0], Status[Status>0], Context[Status>0], Values[Status>0]\n",
    " \n",
    "\n",
    "\n",
    "# histroy memory of two \n",
    "def history_summary(Status):\n",
    "#     S = [p[0]  for s, p in zip(State, Poss)]\n",
    "    M = np.zeros((len(Status), 2))\n",
    "    m2 = 0\n",
    "    for i, (s1, s2) in enumerate(zip(Status[:-1], Status[1:])): \n",
    "        # if next clicks changes, then store this click as a memory value registed in m2  \n",
    "        if s2 != s1:\n",
    "            m2 = s1\n",
    "        # sore memory,  m0 as memory of stimulus, m1 as memory of second click    \n",
    "        M[i+1, 0] = s2\n",
    "        M[i+1, 1] = m2   \n",
    "#         print (s1)\n",
    "    return M  \n",
    "\n",
    "# transform to time section\n",
    "def Stage_transform(State):\n",
    "    S = np.cumsum([np.sum(s1 != s2) for (s1, s2) in zip(State[:-1], State[1:])] + [1]) \n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to space section\n",
    "def wall_detection(pos, size):\n",
    "    if pos[0] == 2:\n",
    "        Stim = 1\n",
    "    elif pos[0] == 2 + size - 1:\n",
    "        Stim = 2\n",
    "    elif pos[1] == 2:\n",
    "        Stim = 3\n",
    "    elif pos[1] == 2 + size - 1:\n",
    "        Stim = 4\n",
    "    else:\n",
    "        Stim = 0 \n",
    "    return Stim \n",
    "# for the memory feature, a Msimple one is just the last click, a most complicate one should be click sequence     \n",
    "def State_transform(State, Poss, size):\n",
    "#     S = [p[0]  for s, p in zip(State, Poss)]\n",
    "    S = [wall_detection(pos, size) for pos in Poss]\n",
    "    Status = []\n",
    "    s1 = 0\n",
    "    for s in S: \n",
    "        if s != 0: \n",
    "            s1 = s\n",
    "#         print (s1)\n",
    "        Status.append(s1)\n",
    "    return S, Status\n",
    "# histroy memory of two \n",
    "def history_summary(Status):\n",
    "#     S = [p[0]  for s, p in zip(State, Poss)]\n",
    "    M = np.zeros((len(Status), 2))\n",
    "    m2 = 0\n",
    "    for i, (s1, s2) in enumerate(zip(Status[:-1], Status[1:])): \n",
    "        # if next clicks changes, then store this click as a memory value registed in m2  \n",
    "        if s2 != s1:\n",
    "            m2 = s1\n",
    "        # sore memory,  m0 as memory of stimulus, m1 as memory of second click    \n",
    "        M[i+1, 0] = s2\n",
    "        M[i+1, 1] = m2   \n",
    "#         print (s1)\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Feature_preprocessing(States, Poss, Hiddens, Actions, Context, Values, size = 15):\n",
    "    States, Poss, Hiddens, Actions, Status, Context, Values = Transform(States, Poss, Hiddens, \\\n",
    "                                                                        Actions, Context, Values)\n",
    "    x =  Hiddens[:, :512]\n",
    "    z = (x - np.min(x))/(np.max(x) - np.min(x))\n",
    "    y = np.log(z/(1-z + 1e-3) + 1e-3)\n",
    "    A = np.array([np.eye(4)[a] for a in Actions]).reshape(-1, 4)\n",
    "    Y = np.array([(y - size/2.)/size for y in Poss[:, 0] -2]).reshape(-1, 1)\n",
    "    X = np.array([(x - size/2.)/size for x in Poss[:, 1] - 2]).reshape(-1, 1)\n",
    "    M = np.array([np.eye(5)[s] for s in Status]).reshape(-1, 5)\n",
    "    S = np.array([np.eye(5)[s] for s in States]).reshape(-1, 5)\n",
    "#     S = np.array(States).reshape(-1, 9)\n",
    "    C = np.array(Context).reshape(-1, 1)\n",
    "    # S_wall = np.array([np.eye(27)[s] for s in Stim_wall]).reshape(-1, 27)\n",
    "    Features = np.concatenate((A, Y, X, M, S, C), axis = 1)\n",
    "    Features_A = np.concatenate((Y, X, M, S, C), axis = 1)\n",
    "    Features_Y = np.concatenate((A, X, M, S, C), axis = 1)\n",
    "    Features_X = np.concatenate((A, Y, M, S, C), axis = 1)\n",
    "    Features_M = np.concatenate((A, Y, X, S, C), axis = 1)\n",
    "    Features_S = np.concatenate((A, Y, X, M, C), axis = 1)\n",
    "    Features_C = np.concatenate((A, Y, X, M, S), axis = 1)\n",
    "    return y, Features, Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C, Values\n",
    "# State_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record sessions 100 for 2 different context, record the relevant variables \n",
    "def Data_record(weight, k_action = 1, epsilon = 0, size = 15, T = 500, seed_num = 1e3):\n",
    "    PC_traces = []\n",
    "    Hiddens = []\n",
    "    Poss = []\n",
    "    Actions = []\n",
    "    States = []\n",
    "    Context = []\n",
    "    Values = []\n",
    "    for i in range(T):\n",
    "        torch.manual_seed(np.random.randint(seed_num))\n",
    "        hidden0 = torch.randn(1, 512)\n",
    "        c  = np.random.randint(2)\n",
    "        start = (np.random.randint(2, size +2),  np.random.randint(2, size+2))\n",
    "        game = ValueMaxGame(grid_size = (size, size), holes = 0, random_seed = 0 , set_reward = [(0.5, 0.25), (0.5, 0.75)], input_type = 0, discount = 0.9, alpha = 1\n",
    "                           ,lam = 0)\n",
    "        game.net.load_state_dict(torch.load(weight))\n",
    "        game.net.k_action = k_action \n",
    "        grid = game.grid.grid.copy()\n",
    "        Pos, hidden, dh, Action, State, values, reward = trajectory(game, start, reward_control = c, size = size, \\\n",
    "                                                                  test = 0, limit_set = 8, init_hidden = False, hidden = hidden0, epsilon = epsilon, reward = True)\n",
    "        Hiddens.append(hidden)\n",
    "        Poss.append(Pos[1:])\n",
    "        Actions.append(Action)\n",
    "        States.append(State)\n",
    "        Context.append(c * np.ones(len(State)))\n",
    "        Values.append(values)\n",
    "    return States, Poss, Hiddens, Actions, Context, Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Echo Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variance\n",
    "More variance covered by low D variables, corresponding to low D representation shown by PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variance 0.17693367532429446 0.1711914745163429\n",
      "total variance 0.037345342950896594 0.03728601239519795\n",
      "total variance 0.00658277323918352 0.006373825923249893\n",
      "total variance 0.033205552043799255 0.03332728736405183\n",
      "total variance 0.008293855532313854 0.007593933135739911\n",
      "total variance 0.011307513256308088 0.011235243178369946\n",
      "total variance 0.0150953052534061 0.014767615092761404\n"
     ]
    }
   ],
   "source": [
    "# record sessions 100 for 2 different context, record the relevant variables \n",
    "weight ='weights2/rnn_1515tanh512_checkpoint300_0_5'\n",
    "States1, Poss1, Hiddens1, Actions1, Context1, Values1 = Data_record(weight, T = 1000)\n",
    "y, Features, Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C, Values1 = Feature_preprocessing(States1, Poss1, Hiddens1, Actions1,\\\n",
    "                                                                                                           Context1, Values1)\n",
    "clf0 = Lasso(alpha = 1e-2)\n",
    "clf0.fit(Features_A, y)\n",
    "cv_scores_all = cross_validate(clf0, Features, y, cv = 5, scoring=('r2'), return_train_score = True)\n",
    "print ('total variance', np.mean(cv_scores_all['train_score']), np.mean(cv_scores_all['test_score']))\n",
    "importances = []\n",
    "importances_std = []\n",
    "for i, feature in enumerate([Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C]):\n",
    "    clf = Lasso(alpha = 1e-2)\n",
    "    cv_scores = cross_validate(clf, feature, y, cv = 5, scoring=('r2'), return_train_score = True)\n",
    "    print ('total variance', np.mean(cv_scores_all['train_score'] -  cv_scores['train_score']), \\\n",
    "           np.mean(cv_scores_all['test_score'] - cv_scores['test_score']))\n",
    "    importances.append(np.mean(cv_scores_all['test_score'] - cv_scores['test_score']))\n",
    "    importances_std.append(np.std(cv_scores_all['test_score'] - cv_scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x7f839661c240>,\n",
       "  <matplotlib.axis.YTick at 0x7f8398d15d68>],\n",
       " <a list of 2 Text yticklabel objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEDCAYAAADdpATdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8396d366a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.save('importance_pos', importances)\n",
    "np.save('importance_pos_std', importances_std)\n",
    "\n",
    "# 009\n",
    "ax = subplot(1, 1, 1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "imp = np.load('importance_pos.npy')\n",
    "imp_std = np.load('importance_pos_std.npy')\n",
    "plt.bar(np.arange(6), height = imp, yerr = imp_std)\n",
    "plt.xticks([0, 1, 2, 3, 4, 5], ['A', 'Y', 'X', 'M', 'S', 'C'], size = 15)\n",
    "plt.yticks([0, 0.1], size = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain Net2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total variance 0.48801937512183163 0.47862559380930403\n",
      "total variance 0.0054364210886023836 0.0049760003762125745\n",
      "total variance 0.017238618699956965 0.015518189510648095\n",
      "total variance 0.013729599098896428 0.012327570184542547\n",
      "total variance 0.2047673708895889 0.21098770605324338\n",
      "total variance 0.07701052149262691 0.07779149437159348\n",
      "total variance 0.028704327767368153 0.02912998770702563\n"
     ]
    }
   ],
   "source": [
    "weight = 'weights_fix_pre2/weights1/rnn_1515tanh512_checkpoint49_0_9'\n",
    "# loadweight(weight_load = 'weights_cpu8/rnn_1515tanh512_checkpoint{}'.format(trial))\n",
    "States1, Poss1, Hiddens1, Actions1, Context1 = Data_record(weight)\n",
    "y, Features, Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C = Feature_preprocessing(States1, Poss1, Hiddens1, Actions1,\\\n",
    "                                                                                                           Context1)\n",
    "clf = Lasso(alpha = 1e-3)\n",
    "cv_scores_all = cross_validate(clf, Features, y, cv = 5, scoring=('r2'), return_train_score = True)\n",
    "print ('total variance', np.mean(cv_scores_all['train_score']), np.mean(cv_scores_all['test_score']))\n",
    "importances = []\n",
    "importances_std = []\n",
    "for i, feature in enumerate([Features_A, Features_Y, Features_X, Features_M, Features_S, Features_C]):\n",
    "    clf = Lasso(alpha = 1e-3)\n",
    "    cv_scores = cross_validate(clf, feature, y, cv = 5, scoring=('r2'), return_train_score = True)\n",
    "    print ('total variance', np.mean(cv_scores_all['train_score'] -  cv_scores['train_score']), \\\n",
    "           np.mean(cv_scores_all['test_score'] - cv_scores['test_score']))\n",
    "    importances.append(np.mean(cv_scores_all['test_score'] - cv_scores['test_score']))\n",
    "    importances_std.append(np.std(cv_scores_all['test_score'] - cv_scores['test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('importance_49', importances)\n",
    "np.save('importance_49_std', importances_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x7f96a0f92710>,\n",
       "  <matplotlib.axis.YTick at 0x7f96a0e43b70>],\n",
       " <a list of 2 Text yticklabel objects>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEBCAYAAACQbKXWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npIKMvyQVZPwlqSDjL0kFGX9JKuj/AMt7r+67APb3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f96a0dfb748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = subplot(1, 1, 1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "imp = np.load('importance_49.npy')\n",
    "imp_std = np.load('importance_49_std.npy')\n",
    "plt.bar(np.arange(6), height = imp, yerr = imp_std)\n",
    "plt.xticks([0, 1, 2, 3, 4, 5], ['A', 'Y', 'X', 'M', 'S', 'C'], size = 15)\n",
    "plt.yticks([0, 0.1], size = 15)\n",
    "# plt.ylim(0, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a SVM decoder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increasing action 10 times will increase decoding efficientcy by 10 %\n",
    "weight ='weights_cpu/rnn_1515tanh512_checkpoint0'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, k_action = 1, T = 500, seed_num = 1e6, epsilon = 1, size = 15)\n",
    "States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context)\n",
    "X = np.array(Hiddens[Status>1])\n",
    "Y = Status[Status>1]\n",
    "score0 = cross_validate(model, X,Y, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9782879818594105\n"
     ]
    }
   ],
   "source": [
    "# increasing action 10 times will increase decoding efficientcy by 10 %\n",
    "weight ='weights_cpu_pre2/rnn_1515tanh512_checkpoint0'\n",
    "Pretest = PretrainTest(weight, holes = 0, inputs_type = (0, 0))\n",
    "Pretest.loadweight(weight)\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, k_action = 1, T = 500, seed_num = 1e6, epsilon = 1, size = 15)\n",
    "States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context)\n",
    "X = np.array(Hiddens[Status>1])\n",
    "Y = Status[Status>1]\n",
    "score = cross_validate(model, X,Y, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# increasing action 10 times will increase decoding efficientcy by 10 %\n",
    "\n",
    "weight ='weights_cpu/rnn_1515tanh512_checkpoint300'\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, k_action = 1, T = 500, seed_num = 1e6, epsilon = 1, size = 15)\n",
    "States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context)\n",
    "X = np.array(Hiddens[Status>1])\n",
    "Y = Status[Status>1]\n",
    "score_pos = cross_validate(model, X,Y, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_echo = score0['test_score']\n",
    "test_pre2 = score['test_score']\n",
    "test_pos = score_pos['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x7ff40730c588>,\n",
       "  <matplotlib.axis.YTick at 0x7ff4073b2e80>,\n",
       "  <matplotlib.axis.YTick at 0x7ff4073128d0>],\n",
       " <a list of 3 Text yticklabel objects>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEBCAYAAACQbKXWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff414116048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = subplot(1, 1, 1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "barlist = plt.bar(np.arange(3), height = [np.mean(test_echo), np.mean(test_pos), np.mean(test_pre2)], yerr =  [np.std(test_echo), np.std(test_pos), np.std(test_pre2)])\n",
    "barlist[0].set_color('b')\n",
    "barlist[1].set_color('r')\n",
    "barlist[2].set_color('g')\n",
    "plt.xticks([0, 1, 2], ['echo', 'PosNet', 'MemNet'], size = 15)\n",
    "plt.yticks([0, 0.5, 1], size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07706672412554766"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(np.array(y_test)//15 - model.predict(X_test)//15).mean() + np.abs(np.array(y_test)%15 -  model.predict(X_test)%15).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6447786721873939\n"
     ]
    }
   ],
   "source": [
    "# increasing action 10 times will increase decoding efficientcy by 10 %\n",
    "weight ='weights_cpu/rnn_1515tanh512_checkpoint0'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, k_action = 1, T = 500, seed_num = 1e6, epsilon = 0.5, size  =15)\n",
    "States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context)\n",
    "X = np.array(Hiddens[Status>1])\n",
    "Y = [p[0]/15 for p in Poss[Status>1]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.9, random_state=30)\n",
    " \n",
    "model = sklearn.linear_model.Lasso(alpha=1e-3)\n",
    "model.fit(X_train, y_train)\n",
    "print (r2_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6992427838530717\n"
     ]
    }
   ],
   "source": [
    "# increasing action 10 times will increase decoding efficientcy by 10 %\n",
    "weight ='weights_cpu/rnn_1515tanh512_checkpoint300'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, k_action = 1, T = 500, seed_num = 1e6, epsilon = 0.5, size  =15)\n",
    "States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context)\n",
    "X = np.array(Hiddens[Status>1])\n",
    "Y = [p[0]/15 for p in Poss[Status>1]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.9, random_state=30)\n",
    " \n",
    "model = sklearn.linear_model.Lasso(alpha=1e-3)\n",
    "model.fit(X_train, y_train)\n",
    "print (r2_score(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13342626842487867"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(np.array(y_test)//15 - model.predict(X_test)//15).mean() + np.abs(np.array(y_test)%15 -  model.predict(X_test)%15).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.039778307843412374\n"
     ]
    }
   ],
   "source": [
    "# increasing action 10 times will increase decoding efficientcy by 10 %\n",
    "weight ='weights_fix/weights1/rnn_1515tanh512_checkpoint39_0_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, k_action = 1, T = 800, seed_num = 1e6, epsilon = 1)\n",
    "States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context)\n",
    "X = np.array(Hiddens[Status>0][:-2])\n",
    "Y = [p[1] + p[0] * 15 for p in Poss[Status>0][2:]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "gammas = [1e-2]\n",
    "for gamma in gammas:\n",
    "    model1 = sklearn.svm.SVC(C = 1e5, gamma = gamma, kernel = 'linear')\n",
    "    model1.fit(X_train, y_train)\n",
    "    print (f1_score(y_test, model1.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(np.array(y_test[:100])//15 - model1.predict(X_test[:100])//15).mean() + np.abs(np.array(y_test[:100])%15 -  model1.predict(X_test[:100])%15).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0569691829233814\n"
     ]
    }
   ],
   "source": [
    "# increasing action 10 times will increase decoding efficientcy by 10 %\n",
    "weight ='weights_fix/weights1/rnn_1515tanh512_checkpoint39_0_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, k_action = 1, T = 800, seed_num = 1e6, epsilon = 1)\n",
    "States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context)\n",
    "X = np.array(Hiddens[Status>0])\n",
    "Y = [p[1] + p[0] * 15 for p in Poss[Status>0]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "gammas = [1e-2]\n",
    "for gamma in gammas:\n",
    "    model1 = sklearn.svm.SVC(C = 1e5, gamma = gamma, kernel = 'linear')\n",
    "    model1.fit(X_train, y_train)\n",
    "    print (f1_score(y_test, model1.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.45"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(np.array(y_test[:100])//15 - model1.predict(X_test[:100])//15).mean() + np.abs(np.array(y_test[:100])%15 -  model1.predict(X_test[:100])%15).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06090251464002756\n"
     ]
    }
   ],
   "source": [
    "weight ='weights_fix_pre2/weights1/rnn_1515tanh512_checkpoint49_1_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, k_action = 1, epsilon = 1, T = 800, seed_num = 1e6)\n",
    "States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context)\n",
    "X = np.array(Hiddens[Status>0])\n",
    "Y = [p[1] + p[0] * 15 for p in Poss[Status>0]]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "gammas = [1e-2]\n",
    "for gamma in gammas:\n",
    "    model1 = sklearn.svm.SVC(C = 1e5, gamma = gamma, kernel = 'linear')\n",
    "    model1.fit(X_train, y_train)\n",
    "    print (f1_score(y_test, model1.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.43"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(np.array(y_test[:100])//15 - model1.predict(X_test[:100])//15).mean() + np.abs(np.array(y_test[:100])%15 -  model1.predict(X_test[:100])%15).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6783576308190717\n"
     ]
    }
   ],
   "source": [
    "weight ='weights_fix/weights1/rnn_1515tanh512_checkpoint0_0_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, k_action = 1, epsilon = 1, T = 800, seed_num = 1e6, size = 30)\n",
    "States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context, size = 15)\n",
    "X = np.array(Hiddens[Status>0])\n",
    "Y = Status[Status>0]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "model = sklearn.linear_model.LogisticRegression(C = 1e5)\n",
    "model.fit(X_train, y_train)\n",
    "print (f1_score(y_test, model.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.630360236150882\n"
     ]
    }
   ],
   "source": [
    "weight ='weights_fix/weights1/rnn_1515tanh512_checkpoint39_0_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, k_action = 1, epsilon = 1, T = 800, seed_num = 1e6, size = 30)\n",
    "States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context, size = 15)\n",
    "X = np.array(Hiddens[Status>0])\n",
    "Y = Status[Status>0]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "model = sklearn.linear_model.LogisticRegression(C = 1e5)\n",
    "model.fit(X_train, y_train)\n",
    "print (f1_score(y_test, model.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'weights_fix_pre2/weights1/rnn_1515tanh512_checkpoint49_1_9'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a317263ab427>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'weights_fix_pre2/weights1/rnn_1515tanh512_checkpoint49_1_9'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# # change weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mStates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mContext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mStates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mContext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHiddens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-c0d96b60e7ba>\u001b[0m in \u001b[0;36mData_record\u001b[0;34m(weight, k_action, epsilon, size, T, seed_num)\u001b[0m\n\u001b[1;32m     14\u001b[0m         game = ValueMaxGame(grid_size = (size, size), holes = 0, random_seed = 0 , set_reward = [(0.5, 0.25), (0.5, 0.75)], input_type = 0, discount = 0.9, alpha = 1\n\u001b[1;32m     15\u001b[0m                            ,lam = 0)\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_action\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk_action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'weights_fix_pre2/weights1/rnn_1515tanh512_checkpoint49_1_9'"
     ]
    }
   ],
   "source": [
    "weight ='weights_fix_pre2/weights1/rnn_1515tanh512_checkpoint49_1_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, k_action = 1, epsilon = 1, T = 800, seed_num = 1e6, size = 50)\n",
    "States, Poss, Hiddens, Actions, Status, Context = Transform(States, Poss, Hiddens, Actions, Context, size = 15)\n",
    "X = np.array(Hiddens[Status>0])\n",
    "Y = Status[Status>0]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "model = sklearn.linear_model.LogisticRegression(C = 1e5)\n",
    "model.fit(X_train, y_train)\n",
    "print (f1_score(y_test, model.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8517792098627066\n"
     ]
    }
   ],
   "source": [
    "weight ='weights_fix/weights1/rnn_1515tanh512_checkpoint0_0_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, epsilon = 1, k_action = 1, T = 400, seed_num = 1e6)\n",
    "States, Poss, Hiddens, Actions, Status, Context, Memory = Transform(States, Poss, Hiddens, Actions, Context, history = True)\n",
    "\n",
    "Mem = np.array([mem[1] + 4 * mem[0] for mem in Memory])\n",
    "\n",
    "X = np.array(Hiddens[Status>0])\n",
    "Y = Mem[Status>0]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "gammas = [1e-2]\n",
    "for gamma in gammas:\n",
    "    model1 = sklearn.svm.SVC(C = 1e5, gamma = gamma, kernel = 'linear')\n",
    "    model1.fit(X_train, y_train)\n",
    "    print (f1_score(y_test, model1.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6976256983240223\n"
     ]
    }
   ],
   "source": [
    "weight ='weights_fix/weights1/rnn_1515tanh512_checkpoint39_0_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, epsilon = 1, k_action = 1, T = 400, seed_num = 1e6)\n",
    "States, Poss, Hiddens, Actions, Status, Context, Memory = Transform(States, Poss, Hiddens, Actions, Context, history = True)\n",
    "\n",
    "Mem = np.array([mem[1] + 4 * mem[0] for mem in Memory])\n",
    "\n",
    "X = np.array(Hiddens[Status>0])\n",
    "Y = Mem[Status>0]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "gammas = [1e-2]\n",
    "for gamma in gammas:\n",
    "    model1 = sklearn.svm.SVC(C = 1e5, gamma = gamma, kernel = 'linear')\n",
    "    model1.fit(X_train, y_train)\n",
    "    print (f1_score(y_test, model1.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7255192878338279\n"
     ]
    }
   ],
   "source": [
    "weight ='weights_fix_pre2/weights1/rnn_1515tanh512_checkpoint49_1_9'\n",
    "# # change weights\n",
    "States, Poss, Hiddens, Actions, Context = Data_record(weight, epsilon = 1, k_action = 1, T = 400, seed_num = 1e6)\n",
    "States, Poss, Hiddens, Actions, Status, Context, Memory = Transform(States, Poss, Hiddens, Actions, Context, history = True)\n",
    "\n",
    "Mem = np.array([mem[1] + 4 * mem[0] for mem in Memory])\n",
    "\n",
    "X = np.array(Hiddens[Status>0])\n",
    "Y = Mem[Status>0]\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.5, random_state=30)\n",
    " \n",
    "gammas = [1e-2]\n",
    "for gamma in gammas:\n",
    "    model1 = sklearn.svm.SVC(C = 1e5, gamma = gamma, kernel = 'linear')\n",
    "    model1.fit(X_train, y_train)\n",
    "    print (f1_score(y_test, model1.predict(X_test), average = 'micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "**The strongest property of pretrain net, no matter it is in the obstacle case or no hole case, is the strong presence of position/x signal in the code **"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "759px",
    "left": "0px",
    "right": "1228px",
    "top": "67px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
