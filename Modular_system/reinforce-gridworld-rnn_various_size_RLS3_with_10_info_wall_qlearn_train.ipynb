{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#quick-start\" data-toc-modified-id=\"quick-start-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>quick start</a></span><ul class=\"toc-item\"><li><span><a href=\"#Resources\" data-toc-modified-id=\"Resources-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Resources</a></span></li></ul></li><li><span><a href=\"#FULL-MODEL\" data-toc-modified-id=\"FULL-MODEL-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>FULL MODEL</a></span><ul class=\"toc-item\"><li><span><a href=\"#Packages\" data-toc-modified-id=\"Packages-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Packages</a></span><ul class=\"toc-item\"><li><span><a href=\"#Qnetwork\" data-toc-modified-id=\"Qnetwork-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Qnetwork</a></span></li></ul></li><li><span><a href=\"#POMDP-RNN-Game\" data-toc-modified-id=\"POMDP-RNN-Game-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>POMDP RNN Game</a></span></li><li><span><a href=\"#Results\" data-toc-modified-id=\"Results-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Results</a></span><ul class=\"toc-item\"><li><span><a href=\"#Standard-setting：-grid-=--(3,7)，-holes-=-0\" data-toc-modified-id=\"Standard-setting：-grid-=--(3,7)，-holes-=-0-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Standard setting： grid =  (3,7)， holes = 0</a></span></li><li><span><a href=\"#Model-Tranining\" data-toc-modified-id=\"Model-Tranining-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Model Tranining</a></span></li><li><span><a href=\"#decoding-vs-performance\" data-toc-modified-id=\"decoding-vs-performance-2.3.3\"><span class=\"toc-item-num\">2.3.3&nbsp;&nbsp;</span>decoding vs performance</a></span></li><li><span><a href=\"#learning-rate-vs-performance\" data-toc-modified-id=\"learning-rate-vs-performance-2.3.4\"><span class=\"toc-item-num\">2.3.4&nbsp;&nbsp;</span>learning rate vs performance</a></span></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-2.3.5\"><span class=\"toc-item-num\">2.3.5&nbsp;&nbsp;</span>Summary</a></span></li><li><span><a href=\"#Anlytic-part-,-check-the-behaviour-correspond-to-each-decoding-level-and-explain-why\" data-toc-modified-id=\"Anlytic-part-,-check-the-behaviour-correspond-to-each-decoding-level-and-explain-why-2.3.6\"><span class=\"toc-item-num\">2.3.6&nbsp;&nbsp;</span>Anlytic part , check the behaviour correspond to each decoding level and explain why</a></span></li></ul></li><li><span><a href=\"#PCA\" data-toc-modified-id=\"PCA-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>PCA</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quick start "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test what is the decoding change for single size training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "* [*The* Reinforcement learning book from Sutton & Barto](http://incompleteideas.net/sutton/book/the-book-2nd.html)\n",
    "* [The REINFORCE paper from Ronald J. Williams (1992)](http://www-anw.cs.umass.edu/~barto/courses/cs687/williams92simple.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULL MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import init\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import POMDPgame_bars\n",
    "from POMDPgame_bars import*\n",
    "\n",
    "import POMDPgame_basic\n",
    "from POMDPgame_basic import*\n",
    "\n",
    "import POMDPgame_holes\n",
    "from POMDPgame_holes import*\n",
    "\n",
    "\n",
    "import RNN\n",
    "from RNN import *\n",
    "\n",
    "import navigation2\n",
    "from navigation2 import*\n",
    "\n",
    "import Nets\n",
    "from Nets import*\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qnetwork\n",
    "\n",
    "To select actions we take maximum of Q value, corresponding to certain move."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the liquid state approach to work, you need a lot of neurons as surplus or enough hidden to hidden connectivity to make it have an effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  POMDP RNN Game\n",
    "\n",
    "In this game , we use a new reward function determined by game, if the agent achieves the goal before 50, reward is 1. If time pass 50 reward is 0.5, once time pass 100 agent gets a reward of -0.5 .  Practically, this is found to be easier to learn than the rewards as a continous function of time.  Tf the agent learns to search in a efficient way, the largest possible way for search is to firstly arrive at corner then goes to the goal, which, takes about 50 steps, it is reasonble to make 50 and 100 as milestone thing.  Also in principe as the game doesn't have a timer , it is not if it can use a reward as funtion of time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 condition for ending , when pass time limit, game over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For weight update, it seems to be better do it after episode, as it makes non-sense evaluate strategy during episode, but a the end. Also, it is much quicker. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A programming of MDP here, hidden state is as state of enviroment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task <class 'POMDPgame_basic.GameBasic'>\n",
      "task <class 'POMDPgame_holes.GameHole'>\n",
      "task <class 'POMDPgame_bars.GameBar'>\n",
      "task <class 'POMDPgame_scale.GameScale'>\n",
      "task <class 'POMDPgame_scale_x.GameScale_x'>\n",
      "task <class 'POMDPgame_scale_y.GameScale_y'>\n",
      "task <class 'POMDPgame_implicit.GameImplicit'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f887cda8450>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 515.368x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x742.737 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "basicgame = CreateGame(GameBasic, holes = 0)\n",
    "basicgame.reset(size = 15, reward_control=0)\n",
    "plt.matshow(basicgame.grid.grid)\n",
    "\n",
    "holegame = CreateGame(GameHole, holes = 50)\n",
    "holegame.reset(size = 15, reward_control=0)\n",
    "plt.matshow(holegame.grid.grid)\n",
    "\n",
    "bargame = CreateGame(GameBar, holes = 0)\n",
    "bargame.reset(size = 15, reward_control=0)\n",
    "plt.matshow(bargame.grid.grid)\n",
    "\n",
    "scalegame = CreateGame(GameScale, holes = 0)\n",
    "scalegame.reset(reward_control=0)\n",
    "plt.matshow(scalegame.grid.grid)\n",
    "\n",
    "scalegame_x = CreateGame(GameScale_x, holes = 0)\n",
    "scalegame_x.reset(reward_control=0)\n",
    "plt.matshow(scalegame_x.grid.grid)\n",
    "\n",
    "scalegame_y = CreateGame(GameScale_y, holes = 0)\n",
    "scalegame_y.reset(reward_control=0)\n",
    "plt.matshow(scalegame_y.grid.grid)\n",
    "\n",
    "Imp_game = CreateGame(GameImplicit, holes = 0)\n",
    "Imp_game.reset(size = 15, reward_control=0)\n",
    "plt.matshow(Imp_game.grid.grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task <class 'POMDPgame_basic.GameBasic'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-251d5285883d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbasicgame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCreateGame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGameBasic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mholes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'weights_cpu_pos/rnn_1515tanh512_checkpoint399'\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mweight2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'weights_cpu_mem/rnn_1515tanh512_checkpoint49'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbasicgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_control\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasicgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/NavigationPaper/NavigationPaper_925/Modular_system/navigation2.py\u001b[0m in \u001b[0;36mCreateGame\u001b[0;34m(Game, holes, implicit, noise, task, weight1, weight2)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'clear session data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m     \u001b[0mgame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mValueMaxGame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mholes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mholes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_reward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_type\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/NavigationPaper/NavigationPaper_925/Modular_system/navigation2.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, e, holes, grid_size, random_seed, set_reward, time_limit, input_type, lam, discount, alpha, implicit, task, weight1, weight2)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight1\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mweight2\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadweight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitAction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/NavigationPaper/NavigationPaper_925/Modular_system/modules_net.py\u001b[0m in \u001b[0;36mloadweight\u001b[0;34m(self, weight1, weight2)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m#load net2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mnet_dict2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mlist_modules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h2h'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_dict2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'h2h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'a2h'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_dict2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a2h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'i2h'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_dict2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'i2h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'r2h'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_dict2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'r2h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'bh'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet_dict2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bh'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mselect_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_modules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    534\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_torch_load_uninitialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m                 \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroot_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mview_metadata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m     80\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "basicgame = CreateGame(GameBasic, holes = 0, weight1 = 'weights_cpu_pos/rnn_1515tanh512_checkpoint399' , weight2 = 'weights_cpu_mem/rnn_1515tanh512_checkpoint49')\n",
    "basicgame.reset(size = 15, reward_control=0)\n",
    "plt.matshow(basicgame.grid.grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of how to make this traning stable, adding exploration noise , intenral noise or environmental variability like multiple mazes  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic\n",
      "start [15]\n",
      "clear session data 49 2312249344\n",
      "basic performance -0.4362678030755621\n",
      "clear session data 49 2267299840\n",
      "basic performance 0.7863129466682323\n",
      "clear session data 49 2229624832\n",
      "basic performance 0.8822660454237549\n",
      "clear session data 49 2229624832\n",
      "basic performance 0.7897966028011119\n",
      "clear session data 49 2229624832\n",
      "basic performance 0.8801521127266848\n",
      "clear session data 49 2229624832\n",
      "basic performance 0.8884561716324313\n",
      "clear session data 49 2229624832\n",
      "basic performance 0.8840812047698173\n",
      "clear session data 49 2229624832\n",
      "basic performance 0.8646426871468114\n",
      "clear session data 49 2229624832\n",
      "basic performance 0.867948078965218\n",
      "clear session data 49 2229624832\n",
      "basic performance 0.8985777217841986\n",
      "hole\n",
      "start [15]\n",
      "clear session data 4 9539256320\n",
      "hole performance -0.046962344418426796\n",
      "clear session data 4 9997692928\n",
      "hole performance -0.05627743622210882\n",
      "clear session data 4 10032762880\n",
      "hole performance 0.2890648359464867\n",
      "clear session data 4 10094735360\n",
      "hole performance 0.4680161360623327\n",
      "clear session data 4 10064240640\n",
      "hole performance 0.5748369313325068\n",
      "clear session data 4 10063880192\n",
      "hole performance 0.5905884678378085\n",
      "clear session data 4 9972281344\n",
      "hole performance 0.637513409084698\n",
      "clear session data 4 10034253824\n",
      "hole performance 0.6684025838434573\n",
      "clear session data 4 9940344832\n",
      "hole performance 0.6686451135329318\n",
      "clear session data 4 10032775168\n",
      "hole performance 0.7284029858983271\n",
      "clear session data 4 9941147648\n",
      "hole performance 0.7326780864795088\n",
      "clear session data 4 10063654912\n",
      "hole performance 0.723356367076101\n",
      "clear session data 4 10064105472\n",
      "hole performance 0.7320148756385202\n",
      "clear session data 4 10033123328\n",
      "hole performance 0.8196028216906432\n",
      "clear session data 4 10033012736\n",
      "hole performance 0.7869310868470588\n",
      "clear session data 4 10094186496\n",
      "hole performance 0.7787637671420002\n",
      "clear session data 4 9972322304\n",
      "hole performance 0.7914753776115475\n",
      "clear session data 4 10033500160\n",
      "hole performance 0.7952570806352676\n",
      "clear session data 4 9940779008\n",
      "hole performance 0.7727954427952906\n",
      "clear session data 4 10033205248\n",
      "hole performance 0.7991960711272992\n",
      "clear session data 4 9941090304\n",
      "hole performance 0.7898262932707507\n",
      "clear session data 4 10033250304\n",
      "hole performance 0.8183181672641566\n",
      "clear session data 4 10095226880\n",
      "hole performance 0.7764968693873318\n",
      "clear session data 4 9971806208\n",
      "hole performance 0.7893186563608032\n",
      "clear session data 4 10032713728\n",
      "hole performance 0.797296391226451\n",
      "clear session data 4 10007121920\n",
      "hole performance 0.7690765153070214\n",
      "clear session data 4 10033803264\n",
      "hole performance 0.7595226920328692\n",
      "clear session data 4 10005803008\n",
      "hole performance 0.7290843206192132\n",
      "clear session data 4 10033016832\n",
      "hole performance 0.7348163639744094\n",
      "clear session data 4 10033471488\n",
      "hole performance 0.6960217206702675\n",
      "bar\n",
      "start [15]\n",
      "clear session data 49 9971916800\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ValueMaxGame' object has no attribute 'Set_reward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cbb4c63154fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'start'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         Task.qlearn(task, weight_read,  weight_write, episodes = n, noise = 0, size_train = size_train, size_test=[15], iterations = iterations\n\u001b[0;32m---> 23\u001b[0;31m                    , epochs = epochs)\n\u001b[0m",
      "\u001b[0;32m~/Research/PhD/NavigationPaper_905/Tasks/Nets.py\u001b[0m in \u001b[0;36mqlearn\u001b[0;34m(self, task, weight_read, weight_write, episodes, save, size_train, size_test, test_only, noise, k_action, h2o, iterations, epochs)\u001b[0m\n\u001b[1;32m    147\u001b[0m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_write\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;31m# plt.matshow(self.game.grid.grid)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mweight_write\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m             \u001b[0mlam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mrls_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/PhD/NavigationPaper_905/Tasks/Tests.py\u001b[0m in \u001b[0;36mTest\u001b[0;34m(task, game, weight, size)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mperformance\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mTestHole\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_control\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mholes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'bar'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mperformance\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mTestBar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_control\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'scale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mperformance\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mTestScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_control\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/PhD/NavigationPaper_905/Tasks/Tests.py\u001b[0m in \u001b[0;36mTestBar\u001b[0;34m(game, reward_control, cross, size, test, limit_set, map_set, start)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mpos_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSet_reward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_control\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Down\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ValueMaxGame' object has no attribute 'Set_reward'"
     ]
    }
   ],
   "source": [
    "# moving bar train, noise = 0.0\n",
    "trial = 399\n",
    "tasks = ['basic', 'hole']\n",
    "episodes = [10, 30, 30, 10, 30, 30, 30]\n",
    "# iterations = [1, 1, 1, 1, 1, 1, 1]\n",
    "for n, task in zip(episodes, tasks):\n",
    "        Task =  MultipleTasks(task = task, weight_write = 'weights_cpu/rnn_1515tanh512_checkpoint{}'.format(trial)\\\n",
    "                              , noise = 0.0)\n",
    "        weight_read = Task.weight\n",
    "        weight_write = 'weights_' + task + '/rnn_1515tanh512_checkpoint{}'.format(trial)\n",
    "        if task == 'scale':\n",
    "            size_train = np.arange(10, 51, 10)\n",
    "        else:\n",
    "            size_train = [15]\n",
    "        if task == 'hole':\n",
    "            iterations = 5\n",
    "            epochs = 100\n",
    "        else:\n",
    "            iterations = 50\n",
    "            epochs = 10\n",
    "        print ('start', size_train)\n",
    "        Task.qlearn(task, weight_read,  weight_write, episodes = n, noise = 0, size_train = size_train, size_test=[15], iterations = iterations\n",
    "                   , epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bar\n",
      "start [15]\n",
      "clear session data 4 17593364480\n",
      "bar performance -0.7213541666666667\n",
      "clear session data 4 17593364480\n",
      "bar performance -0.6455488445378151\n",
      "clear session data 4 17593364480\n",
      "bar performance -0.5384385131152372\n",
      "clear session data 4 17593364480\n",
      "bar performance -0.48932291666666666\n",
      "clear session data 4 17593364480\n",
      "bar performance -0.43525874035384904\n",
      "clear session data 4 17593364480\n",
      "bar performance -0.43126860119047616\n",
      "clear session data 4 17593364480\n",
      "bar performance -0.380967567431562\n",
      "clear session data 4 17593364480\n",
      "bar performance -0.33281926406926404\n",
      "clear session data 4 17593364480\n",
      "bar performance -0.3671640037593985\n",
      "clear session data 4 17593364480\n",
      "bar performance -0.3185374376780627\n",
      "clear session data 4 17593364480\n",
      "bar performance -0.21723211684149182\n",
      "clear session data 4 17593364480\n",
      "bar performance -0.015000949571262079\n",
      "clear session data 4 17593364480\n",
      "bar performance -0.08231894841269842\n",
      "clear session data 4 17593364480\n",
      "bar performance -0.07905362866300361\n",
      "clear session data 4 17593364480\n",
      "bar performance 0.1619182831970661\n",
      "clear session data 4 17593364480\n",
      "bar performance 0.13501706626706628\n",
      "clear session data 4 17593364480\n",
      "bar performance 0.08407542977855478\n",
      "clear session data 4 17593364480\n",
      "bar performance 0.07601604125041628\n",
      "clear session data 4 17593364480\n",
      "bar performance 0.27046855054667557\n",
      "clear session data 4 17593364480\n",
      "bar performance 0.3391060473091723\n",
      "clear session data 4 17593364480\n",
      "bar performance 0.31204132164530873\n",
      "clear session data 4 17593364480\n",
      "bar performance 0.18251540126540125\n",
      "clear session data 4 17593364480\n",
      "bar performance 0.3703517576173826\n",
      "clear session data 4 17593364480\n",
      "bar performance 0.27764742441466583\n",
      "clear session data 4 17593364480\n",
      "bar performance 0.37812953031164237\n",
      "clear session data 4 17593364480\n",
      "bar performance 0.41917124721542826\n",
      "clear session data 4 17593364480\n",
      "bar performance 0.2980561172842962\n",
      "clear session data 4 17593364480\n",
      "bar performance 0.21313816391941393\n",
      "clear session data 4 17593364480\n",
      "bar performance 0.3878335851195906\n",
      "clear session data 4 17593364480\n",
      "bar performance 0.37408163306600806\n",
      "scale\n",
      "start [10 20 30 40 50]\n"
     ]
    }
   ],
   "source": [
    "# moving bar train, noise = 0.0\n",
    "trial = 399\n",
    "tasks = ['bar']\n",
    "episodes = [30]\n",
    "# iterations = [1, 1, 1, 1, 1, 1, 1]\n",
    "for n, task in zip(episodes, tasks):\n",
    "        Task =  MultipleTasks(task = task, weight_write = 'weights_cpu/rnn_1515tanh512_checkpoint{}'.format(trial)\\\n",
    "                              , noise = 0.0)\n",
    "        weight_read = Task.weight\n",
    "        weight_write = 'weights_' + task + '/rnn_1515tanh512_checkpoint{}'.format(trial)\n",
    "        if task == 'scale':\n",
    "            size_train = np.arange(10, 51, 10)\n",
    "        else:\n",
    "            size_train = [15]\n",
    "        if (task == 'hole') or (task == 'bar'):\n",
    "            iterations = 5\n",
    "            epochs = 100\n",
    "        else:\n",
    "            iterations = 50\n",
    "            epochs = 10 \n",
    "        print ('start', size_train)\n",
    "        Task.qlearn(task, weight_read,  weight_write, episodes = n, noise = 0, size_train = size_train, size_test=[15], iterations = iterations\n",
    "                   , epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task <class 'POMDPgame_scale.GameScale'>\n",
      "scale\n",
      "start [10 20 30 40 50]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tie/.conda/envs/torch/lib/python3.7/site-packages/torch/tensor.py:339: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear session data 49 4953993216\n",
      "(9, 5)\n",
      "(9, 13)\n",
      "scale performance 0.33611628134796234\n"
     ]
    }
   ],
   "source": [
    "# moving bar train, noise = 0.0\n",
    "trial = 399\n",
    "tasks = ['scale']\n",
    "episodes = [10]\n",
    "# iterations = [1, 1, 1, 1, 1, 1, 1]\n",
    "for n, task in zip(episodes, tasks):\n",
    "        Task =  MultipleTasks(task = task, weight_write = 'weights_cpu/rnn_1515tanh512_checkpoint{}'.format(trial)\\\n",
    "                              , noise = 0.0)\n",
    "        weight_read = Task.weight\n",
    "        weight_write = 'weights_' + task + '/rnn_1515tanh512_checkpoint{}'.format(trial)\n",
    "        if task == 'scale':\n",
    "            size_train = np.arange(10, 51, 10)\n",
    "        else:\n",
    "            size_train = [15]\n",
    "        if (task == 'hole') or (task == 'bar'):\n",
    "            iterations = 5\n",
    "            epochs = 100\n",
    "        else:\n",
    "            iterations = 50\n",
    "            epochs = 10 \n",
    "        print ('start', size_train)\n",
    "        Task.qlearn(task, weight_read,  weight_write, episodes = n, noise = 0, size_train = size_train, size_test=[15], iterations = iterations\n",
    "                   , epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task <class 'POMDPgame_scale_x.GameScale_x'>\n",
      "scale_x\n",
      "start [15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tie/.conda/envs/torch/lib/python3.7/site-packages/torch/tensor.py:339: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear session data 49 1602179072\n",
      "scale_x performance -0.614357049271784\n",
      "clear session data 49 1924890624\n",
      "scale_x performance -0.12836621780830826\n",
      "clear session data 49 1924898816\n",
      "scale_x performance -0.27205386307720514\n",
      "clear session data 49 1925128192\n",
      "scale_x performance 0.2289565362688739\n",
      "clear session data 49 1925128192\n",
      "scale_x performance 0.3723983833774887\n",
      "clear session data 49 1925398528\n",
      "scale_x performance 0.6268584164160191\n",
      "clear session data 49 1925668864\n",
      "scale_x performance 0.20934659639048744\n",
      "clear session data 49 1925808128\n",
      "scale_x performance 0.5387847803096268\n",
      "clear session data 49 1925808128\n",
      "scale_x performance 0.6466461672415948\n",
      "clear session data 49 1925808128\n",
      "scale_x performance 0.6581784130930551\n",
      "clear session data 49 1925808128\n",
      "scale_x performance 0.7641275677648225\n",
      "clear session data 49 1926078464\n",
      "scale_x performance 0.8739386962328441\n",
      "clear session data 49 1926348800\n",
      "scale_x performance 0.7818670661839535\n",
      "clear session data 49 1926348800\n",
      "scale_x performance 0.7978166249188479\n",
      "clear session data 49 1926619136\n",
      "scale_x performance 0.7734947396067984\n",
      "clear session data 49 1926619136\n",
      "scale_x performance 0.5878189990894322\n",
      "clear session data 49 1926619136\n",
      "scale_x performance 0.8319723890608604\n",
      "clear session data 49 1926619136\n",
      "scale_x performance 0.794746771987842\n",
      "clear session data 49 1926619136\n",
      "scale_x performance 0.8575655743877482\n",
      "clear session data 49 1926619136\n",
      "scale_x performance 0.7143507085124319\n",
      "clear session data 49 1926889472\n",
      "scale_x performance 0.7632832983317388\n",
      "clear session data 49 1927000064\n",
      "scale_x performance 0.829661704610472\n",
      "clear session data 49 1927000064\n",
      "scale_x performance 0.7440576681588773\n",
      "clear session data 49 1927000064\n",
      "scale_x performance 0.7894180577008618\n",
      "clear session data 49 1927000064\n",
      "scale_x performance 0.8038350046422484\n",
      "clear session data 49 1927000064\n",
      "scale_x performance 0.749031875038209\n",
      "clear session data 49 1927000064\n",
      "scale_x performance 0.5882537527880648\n",
      "clear session data 49 1927000064\n",
      "scale_x performance 0.6085816198259042\n",
      "clear session data 49 1927270400\n",
      "scale_x performance 0.3850398018392009\n",
      "clear session data 49 1927532544\n",
      "scale_x performance 0.3238181809915147\n",
      "task <class 'POMDPgame_scale_y.GameScale_y'>\n",
      "scale_y\n",
      "start [15]\n",
      "clear session data 49 1550450688\n",
      "scale_y performance -0.5560723298315322\n",
      "clear session data 49 1889357824\n",
      "scale_y performance -0.4011668009233818\n",
      "clear session data 49 1889628160\n",
      "scale_y performance 0.12202925902758979\n",
      "clear session data 49 1889628160\n",
      "scale_y performance 0.39929862424361046\n",
      "clear session data 49 1889628160\n",
      "scale_y performance -0.08844071550811587\n",
      "clear session data 49 1889890304\n",
      "scale_y performance -0.3895168047702663\n",
      "clear session data 49 1889628160\n",
      "scale_y performance 0.03810792497182805\n",
      "clear session data 49 1889628160\n",
      "scale_y performance -0.1214133632915887\n"
     ]
    }
   ],
   "source": [
    "# moving bar train, noise = 0.0\n",
    "trial = 399\n",
    "tasks = ['scale_x']\n",
    "episodes = [30]\n",
    "# iterations = [1, 1, 1, 1, 1, 1, 1]\n",
    "for n, task in zip(episodes, tasks):\n",
    "        Task =  MultipleTasks(task = task, weight_write = 'weights_cpu/rnn_1515tanh512_checkpoint{}'.format(trial)\\\n",
    "                              , noise = 0.0)\n",
    "        weight_read = Task.weight\n",
    "        weight_write = 'weights_' + task + '/rnn_1515tanh512_checkpoint{}'.format(trial)\n",
    "        if task == 'scale':\n",
    "            size_train = np.arange(10, 51, 10)\n",
    "        else:\n",
    "            size_train = [15]\n",
    "        if (task == 'hole') or (task == 'bar'):\n",
    "            iterations = 5\n",
    "            epochs = 100\n",
    "        else:\n",
    "            iterations = 50\n",
    "            epochs = 10 \n",
    "        print ('start', size_train)\n",
    "        Task.qlearn(task, weight_read,  weight_write, episodes = n, noise = 0, size_train = size_train, size_test=[15], iterations = iterations\n",
    "                   , epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task <class 'POMDPgame_scale_y.GameScale_y'>\n",
      "scale_y\n",
      "start [15]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tie/.conda/envs/torch/lib/python3.7/site-packages/torch/tensor.py:339: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear session data 49 1552498688\n",
      "scale_y performance -0.1475947715941989\n",
      "clear session data 49 1778864128\n",
      "scale_y performance -0.2568936771122899\n",
      "clear session data 49 1822928896\n",
      "scale_y performance 0.34495650120797283\n",
      "clear session data 49 1823211520\n",
      "scale_y performance -0.029815214737947265\n",
      "clear session data 49 1823600640\n",
      "scale_y performance 0.17786481313832003\n",
      "clear session data 49 1823379456\n",
      "scale_y performance -0.17192887958217834\n",
      "clear session data 49 1823395840\n",
      "scale_y performance 0.04712986734727899\n",
      "clear session data 49 1823666176\n",
      "scale_y performance -0.1566897530812853\n",
      "clear session data 49 1823846400\n",
      "scale_y performance -0.09202431204261699\n",
      "clear session data 49 1823850496\n",
      "scale_y performance -0.09731937396222021\n",
      "clear session data 49 1824112640\n",
      "scale_y performance -0.2861627606267684\n",
      "clear session data 49 1824124928\n",
      "scale_y performance -0.4148447350206051\n",
      "clear session data 49 1899950080\n",
      "scale_y performance -0.3400537790079993\n",
      "clear session data 49 1899950080\n",
      "scale_y performance -0.21973814955865673\n",
      "clear session data 49 2012225536\n",
      "scale_y performance -0.36923393330052845\n",
      "clear session data 49 2012495872\n",
      "scale_y performance -0.31388688228417927\n",
      "clear session data 49 2013016064\n",
      "scale_y performance -0.011655137295458029\n",
      "clear session data 49 2013016064\n",
      "scale_y performance -0.409085634574022\n",
      "clear session data 49 2013024256\n",
      "scale_y performance -0.4646520961232352\n",
      "clear session data 49 2013286400\n",
      "scale_y performance -0.597283768280795\n",
      "clear session data 49 2121138176\n",
      "scale_y performance -0.5681285233219853\n",
      "clear session data 49 2121138176\n",
      "scale_y performance -0.13901090234118918\n",
      "clear session data 49 2121138176\n",
      "scale_y performance -0.22329000456301723\n",
      "clear session data 49 2121138176\n",
      "scale_y performance -0.15842937539442054\n",
      "clear session data 49 2121408512\n",
      "scale_y performance -0.14174776688944754\n",
      "clear session data 49 2121408512\n",
      "scale_y performance -0.5592541315718207\n",
      "clear session data 49 2121670656\n",
      "scale_y performance -0.2562418077803595\n",
      "clear session data 49 2173186048\n",
      "scale_y performance -0.5470125659635193\n",
      "clear session data 49 2121760768\n",
      "scale_y performance -0.22331028692386345\n",
      "clear session data 49 2121498624\n",
      "scale_y performance -0.34426547712030464\n"
     ]
    }
   ],
   "source": [
    "# moving bar train, noise = 0.0\n",
    "trial = 399\n",
    "tasks = ['scale_y']\n",
    "episodes = [30]\n",
    "# iterations = [1, 1, 1, 1, 1, 1, 1]\n",
    "for n, task in zip(episodes, tasks):\n",
    "        Task =  MultipleTasks(task = task, weight_write = 'weights_cpu/rnn_1515tanh512_checkpoint{}'.format(trial)\\\n",
    "                              , noise = 0.0)\n",
    "        weight_read = Task.weight\n",
    "        weight_write = 'weights_' + task + '/rnn_1515tanh512_checkpoint{}'.format(trial)\n",
    "        if task == 'scale':\n",
    "            size_train = np.arange(10, 51, 10)\n",
    "        else:\n",
    "            size_train = [15]\n",
    "        if (task == 'hole') or (task == 'bar'):\n",
    "            iterations = 5\n",
    "            epochs = 100\n",
    "        else:\n",
    "            iterations = 50\n",
    "            epochs = 10 \n",
    "        print ('start', size_train)\n",
    "        Task.qlearn(task, weight_read,  weight_write, episodes = n, noise = 0, size_train = size_train, size_test=[15], iterations = iterations\n",
    "                   , epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task <class 'POMDPgame_scale_xy.GameScale_xy'>\n",
      "scale_xy\n",
      "start [15] 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tie/.conda/envs/torch/lib/python3.7/site-packages/torch/tensor.py:339: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear session data 49 2989703168\n",
      "scale_xy performance -0.5210801823640594\n",
      "clear session data 49 12056076288\n",
      "scale_xy performance -0.27990230575743485\n",
      "clear session data 49 12056084480\n"
     ]
    }
   ],
   "source": [
    "# moving bar train noise 0.2\n",
    "trial = 399\n",
    "tasks = [ 'scale_xy']\n",
    "episodes = [30]\n",
    "# iterations = [1, 1, 1, 1, 1, 1, 1]\n",
    "for n, task in zip(episodes, tasks):\n",
    "        Task =  MultipleTasks(task = task, weight_write = 'weights_cpu/rnn_1515tanh512_checkpoint{}'.format(trial)\\\n",
    "                              , noise = 0.0)\n",
    "        weight_read = Task.weight\n",
    "        weight_write = 'weights_' + task + '/rnn_1515tanh512_checkpoint{}'.format(trial)\n",
    "        if task == 'scale':\n",
    "            size_train = np.arange(10, 51, 10)\n",
    "        else:\n",
    "            size_train = [15]\n",
    "        if (task == 'hole') or (task == 'bar'):\n",
    "            iterations = 5\n",
    "            epochs = 100\n",
    "            print ('hole', iterations, epochs)\n",
    "        else:\n",
    "            iterations = 50\n",
    "            epochs = 20\n",
    "        print ('start', size_train, Task.game.holes)\n",
    "        Task.qlearn(task, weight_read,  weight_write, episodes = n, noise = 0, size_train = size_train, size_test=[15], iterations = iterations\n",
    "                   , epochs = epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### measure decoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoding accuracy decreases, there are two possible reasons: \n",
    "1, decoding has bias,  information of position is only refleted by decoding, if there is certain bias , it is not trustable\n",
    "2, it is the real measure of information, so there are less spatial information about space, or an effect decoupling/disentanglement of position. This can be due the network succeed at finding an even lower diemnsion object which gives successful performance.  The representation deceases its information to input in a sense. \n",
    "\n",
    "This can be linked to receptive field by looking at how space is represented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "759px",
    "left": "0px",
    "right": "1228px",
    "top": "67px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
